{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/Users/patricia/Documents/code/python-code/behavior-detection/src\"\n",
    "os.chdir(path)  # Muda o diretório para o nível anterior (a raiz do projeto)\n",
    "print(os.getcwd())  # Verifique se agora está na raiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavior.data.behavior_data_loader import BehaviorDataLoader\n",
    "\n",
    "data_path = '../data/new_logs_labels.csv'\n",
    "\n",
    "data = BehaviorDataLoader.load_data(data_path, delimiter=';')\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessors.data_cleaner import DataCleaner\n",
    "\n",
    "print(\"Valores da coluna 'comportamento' antes da remoção:\", data['comportamento'].value_counts())\n",
    "\n",
    "# Remove instances where 'comportamento' is '?'\n",
    "data = DataCleaner.remove_instances_with_value(data, 'comportamento', '?')\n",
    "\n",
    "print(\"\\nValores da coluna 'comportamento' depois da remoção:\", data['comportamento'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select a subset of the data only for testing purposes\n",
    "\n",
    "print(\"Tamanho do dataframe antes:\", data.shape)\n",
    "data, _ = train_test_split(data, test_size=0.2, stratify=data['comportamento'], random_state=42)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(\"Tamanho do dataframe após:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns related to IDs, emotions, personality and behaviors, because \n",
    "# we want to classify behaviors only by the students' interactions with the system\n",
    "columns_to_remove_ids = ['id_log', 'grupo', 'num_dia', 'num_log']\n",
    "columns_to_remove_emotions = [\n",
    "    'estado_afetivo', 'estado_engajamento_concentrado', \n",
    "    'estado_confusao', 'estado_frustracao', 'estado_tedio', 'estado_indefinido', \n",
    "    'ultimo_estado_afetivo', 'ultimo_engajamento_concentrado', 'ultimo_confusao', \n",
    "    'ultimo_frustracao', 'ultimo_tedio', 'ultimo_estado_indefinido'\n",
    "]\n",
    "columns_to_remove_personality = [\n",
    "    'traco_amabilidade_fator', 'traco_extrovercao_fator', 'traco_conscienciosidade_fator', \n",
    "    'traco_abertura_fator', 'traco_neuroticismo_fator', 'traco_amabilidade_cat', \n",
    "    'traco_extrovercao_cat', 'traco_conscienciosidade_cat', 'traco_abertura_cat', \n",
    "    'traco_neuroticismo_cat']\n",
    "\n",
    "columns_to_remove_behaviors = [\n",
    "    'comportamento_on_task', 'comportamento_on_task_conversation', 'comportamento_on_task_out',\n",
    "    'comportamento_off_task', 'comportamento_on_system', 'comportamento_indefinido',\n",
    "    'ultimo_comportamento', 'ultimo_comportamento_on_task', 'ultimo_comportamento_on_task_conversation',\n",
    "    'ultimo_comportamento_on_task_out', 'ultimo_comportamento_off_task', 'ultimo_comportamento_on_system',\n",
    "    'ultimo_comportamento_indefinido'\n",
    "]\n",
    "\n",
    "columns_to_remove = columns_to_remove_ids + \\\n",
    "        columns_to_remove_emotions + \\\n",
    "        columns_to_remove_personality + \\\n",
    "        columns_to_remove_behaviors\n",
    "\n",
    "cleaned_data = DataCleaner.remove_columns(data, columns_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenche valores ausentes no DataFrame X com a string 'missing'.\n",
    "\n",
    "numeric_columns = cleaned_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = cleaned_data.select_dtypes(exclude=['float64', 'int64']).columns\n",
    "\n",
    "cleaned_data[numeric_columns] = cleaned_data[numeric_columns].fillna(cleaned_data[numeric_columns].median())\n",
    "cleaned_data[categorical_columns] = cleaned_data[categorical_columns].fillna('missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data by student level into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessors.data_splitter import DataSplitter\n",
    "\n",
    "train_data, test_data = DataSplitter.split_by_student_level(cleaned_data, test_size=0.2, column_name='aluno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Após o split por nível do estudante\n",
    "print(\"\\n=== Após split por nível do estudante ===\")\n",
    "print(f\"Shape de train_data: {train_data.shape}\")\n",
    "print(\"Colunas em train_data:\", train_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the 'aluno' column from the data after splitting into train and test sets\n",
    "\n",
    "# Remover 'aluno' do conjunto de treinamento\n",
    "train_data = DataCleaner.remove_columns(train_data, ['aluno'])\n",
    "\n",
    "# Remover 'aluno' do conjunto de teste\n",
    "test_data = DataCleaner.remove_columns(test_data, ['aluno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Após remover coluna 'aluno'\n",
    "print(\"\\n1. Após remover 'aluno':\")\n",
    "print(f\"Shape de train_data: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into Features (X) and Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessors.data_splitter import DataSplitter\n",
    "\n",
    "# Conjunto de treinamento\n",
    "X_train, y_train = DataSplitter.split_into_x_y(train_data, 'comportamento')\n",
    "\n",
    "# Conjunto de teste\n",
    "X_test, y_test = DataSplitter.split_into_x_y(test_data, 'comportamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 2. Após split X/y\n",
    "print(\"\\n2. Após split X/y:\")\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    print(f\"Shape de X_train: {X_train.shape}\")\n",
    "    print(\"Primeiras colunas de X_train:\", list(X_train.columns)[:5])\n",
    "else:\n",
    "    print(\"X_train não é um DataFrame!\")\n",
    "    print(f\"Tipo de X_train: {type(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Primeiras 5 instâncias de y_train:\")\n",
    "print(y_train[:5])\n",
    "\n",
    "print(\"\\nPrimeiras 5 instâncias de y_test:\")\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding true labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from core.preprocessors import column_selector, data_encoder\n",
    "from behavior.data import behavior_data_encoder\n",
    "\n",
    "# Recarregar o módulo para garantir que as alterações sejam aplicadas\n",
    "importlib.reload(column_selector)\n",
    "importlib.reload(data_encoder)\n",
    "importlib.reload(behavior_data_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding y_train and y_test\n",
    "from behavior.data.behavior_data_encoder import BehaviorDataEncoder\n",
    "\n",
    "# Codificar y_train\n",
    "y_train = BehaviorDataEncoder.encode_y(y_train)\n",
    "\n",
    "# Codificar y_test\n",
    "y_test = BehaviorDataEncoder.encode_y(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from behavior.data.behavior_data_encoder import BehaviorDataEncoder\n",
    "\n",
    "# Encoding do target (y)\n",
    "y_train = BehaviorDataEncoder.encode_y(y_train)\n",
    "y_test = BehaviorDataEncoder.encode_y(y_test)\n",
    "\n",
    "# Encoding das features (X)\n",
    "print(\"=== Iniciando encoding das features ===\")\n",
    "X_encoder = BehaviorDataEncoder(num_classes=5)\n",
    "print(\"\\nRealizando fit do encoder...\")\n",
    "X_encoder.fit(X_train)\n",
    "\n",
    "print(\"\\nRealizando transform...\")\n",
    "X_train = X_encoder.transform(X_train)\n",
    "\n",
    "print(\"\\nTransformando dados de teste...\")\n",
    "X_test = X_encoder.transform(X_test)\n",
    "\n",
    "# Verificação final\n",
    "print(\"\\n=== Verificação após encoding ===\")\n",
    "print(f\"Shape de X_train: {X_train.shape}\")\n",
    "print(f\"Shape de X_test: {X_test.shape}\")\n",
    "print(f\"Shape de y_train: {y_train.shape}\")\n",
    "print(f\"Shape de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes do SMOTE, adicione estas verificações\n",
    "print(\"Verificando X_train antes do SMOTE:\")\n",
    "print(\"1. Shape de X_train:\", X_train.shape)\n",
    "print(\"2. Tipo de X_train:\", type(X_train))\n",
    "print(\"3. Shape de y_train:\", y_train.shape)\n",
    "print(\"4. Tipo de y_train:\", type(y_train))\n",
    "\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    print(\"5. Colunas em X_train:\")\n",
    "    print(X_train.columns.tolist())\n",
    "    print(\"\\n6. Primeiras linhas de X_train:\")\n",
    "    print(X_train.head())\n",
    "    print(\"\\n7. Tipos de dados das colunas:\")\n",
    "    print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessors.data_balancer import DataBalancer\n",
    "\n",
    "data_balancer = DataBalancer()\n",
    "X_train, y_train = data_balancer.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(f\"Resampled dataset shape: {Counter(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações e configuração de diretório permanecem iguais até a seção de treinamento\n",
    "\n",
    "# Na seção \"Definindo parametros\", substituir:\n",
    "from core.models.multiclass.behavior_model_params import BehaviorModelParams\n",
    "\n",
    "# Criar instância dos parâmetros específicos para comportamentos\n",
    "model_params = BehaviorModelParams()\n",
    "\n",
    "# # Definir quais modelos e seletores utilizar\n",
    "# selected_models = [ \n",
    "#     # 'Logistic Regression',\n",
    "#     'Decision Tree',\n",
    "#     # 'Random Forest',\n",
    "#     # 'Gradient Boosting',\n",
    "#     # 'SVM',\n",
    "#     # 'KNN',\n",
    "#     # 'XGBoost',\n",
    "#     'Naive Bayes' \n",
    "#     # 'MLP'  \n",
    "# ]\n",
    "\n",
    "# # Definir quais seletores de features utilizar\n",
    "# selected_selectors = [\n",
    "#     # 'rfe',      # Recursive Feature Elimination\n",
    "#     'pca',      # Principal Component Analysis\n",
    "#     # 'rf',       # Random Forest Feature Selector\n",
    "#     # 'mi',       # Mutual Information Feature Selector\n",
    "#     'none'      # Sem seleção de features\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Usar todos os modelos disponíveis\n",
    "selected_models = model_params.get_available_models()  # ou lista específica\n",
    "\n",
    "# # Usar todos os seletores disponíveis\n",
    "selected_selectors = None  # None to use all selectors\n",
    "\n",
    "# Configurar validação cruzada estratificada\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Parâmetros de otimização\n",
    "n_iter = 50  # Reduzido para teste inicial\n",
    "n_jobs = 6  # MacBook Air M2 tem 8 núclos CPUs e 10 GPUs. Como uso sciktlearn, só posso usar CPUs. Teria que usar Pytorch ou TensorFlow para usar GPUs\n",
    "scoring_metric = 'balanced_accuracy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Otimização Bayesiana (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.management.stage_training_manager import StageTrainingManager\n",
    "from core.training.optuna_bayesian_optimization_training import OptunaBayesianOptimizationTraining\n",
    "\n",
    "# Definir as etapas incorporando todos os seletores de features\n",
    "stages = [\n",
    "        ('etapa_1_logistic_none', ['Logistic Regression'], ['none']),\n",
    "        ('etapa_2_logistic_pca', ['Logistic Regression'], ['pca']),\n",
    "        ('etapa_3_logistic_rfe', ['Logistic Regression'], ['rfe']),\n",
    "        ('etapa_4_logistic_rf', ['Logistic Regression'], ['rf']),\n",
    "        ('etapa_5_logistic_mi', ['Logistic Regression'], ['mi']),\n",
    "        ('etapa_6_tree_none', ['Decision Tree'], ['none']),\n",
    "        ('etapa_7_tree_pca', ['Decision Tree'], ['pca']),\n",
    "        ('etapa_8_tree_rfe', ['Decision Tree'], ['rfe']),\n",
    "        ('etapa_9_tree_rf', ['Decision Tree'], ['rf']),\n",
    "        ('etapa_10_tree_mi', ['Decision Tree'], ['mi']),\n",
    "        ('etapa_11_rf_none', ['Random Forest'], ['none']),\n",
    "        ('etapa_12_rf_pca', ['Random Forest'], ['pca']),\n",
    "        ('etapa_13_rf_rfe', ['Random Forest'], ['rfe']),\n",
    "        ('etapa_14_rf_rf', ['Random Forest'], ['rf']),\n",
    "        ('etapa_15_rf_mi', ['Random Forest'], ['mi']),\n",
    "        ('etapa_16_gb_none', ['Gradient Boosting'], ['none']),\n",
    "        ('etapa_17_gb_pca', ['Gradient Boosting'], ['pca']),\n",
    "        ('etapa_18_gb_rfe', ['Gradient Boosting'], ['rfe']),\n",
    "        ('etapa_19_gb_rf', ['Gradient Boosting'], ['rf']),\n",
    "        ('etapa_20_gb_mi', ['Gradient Boosting'], ['mi']),\n",
    "        ('etapa_21_svm_none', ['SVM'], ['none']),\n",
    "        ('etapa_22_svm_pca', ['SVM'], ['pca']),\n",
    "        ('etapa_23_svm_rfe', ['SVM'], ['rfe']),\n",
    "        ('etapa_24_svm_rf', ['SVM'], ['rf']),\n",
    "        ('etapa_25_svm_mi', ['SVM'], ['mi']),\n",
    "        ('etapa_26_knn_none', ['KNN'], ['none']),\n",
    "        ('etapa_27_knn_pca', ['KNN'], ['pca']),\n",
    "        ('etapa_28_knn_rfe', ['KNN'], ['rfe']),\n",
    "        ('etapa_29_knn_rf', ['KNN'], ['rf']),\n",
    "        ('etapa_30_knn_mi', ['KNN'], ['mi']),\n",
    "        ('etapa_31_xgb_none', ['XGBoost'], ['none']),\n",
    "        ('etapa_32_xgb_pca', ['XGBoost'], ['pca']),\n",
    "        ('etapa_33_xgb_rfe', ['XGBoost'], ['rfe']),\n",
    "        ('etapa_34_xgb_rf', ['XGBoost'], ['rf']),\n",
    "        ('etapa_35_xgb_mi', ['XGBoost'], ['mi']),\n",
    "        ('etapa_36_nb_none', ['Naive Bayes'], ['none']),\n",
    "        ('etapa_37_nb_pca', ['Naive Bayes'], ['pca']),\n",
    "        ('etapa_38_nb_rfe', ['Naive Bayes'], ['rfe']),\n",
    "        ('etapa_39_nb_rf', ['Naive Bayes'], ['rf']),\n",
    "        ('etapa_40_nb_mi', ['Naive Bayes'], ['mi']),\n",
    "        ('etapa_41_mlp_none', ['MLP'], ['none']),\n",
    "        ('etapa_42_mlp_pca', ['MLP'], ['pca']),\n",
    "        ('etapa_43_mlp_rfe', ['MLP'], ['rfe']),\n",
    "        ('etapa_44_mlp_rf', ['MLP'], ['rf']),\n",
    "        ('etapa_45_mlp_mi', ['MLP'], ['mi'])\n",
    "    ]\n",
    "\n",
    "# Inicializar o gerenciador de treinamento\n",
    "training_manager = StageTrainingManager(\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    model_params=model_params,\n",
    "    n_iter=50,\n",
    "    cv=cv,\n",
    "    scoring=scoring_metric,\n",
    "    n_jobs=n_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    training_manager.execute_all_stages(training_manager, stages)\n",
    "except Exception as e:\n",
    "    print(f\"\\nExecução interrompida: {str(e)}\")\n",
    "    print(\"Você pode executar novamente o mesmo código para retomar do último stage não completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação e logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.reporting import metrics_reporter\n",
    "\n",
    "# Após todas as etapas estarem concluídas:\n",
    "final_results = training_manager.combine_results()\n",
    "training_results, class_metrics, avg_metrics = final_results\n",
    "metrics_reporter.generate_reports(class_metrics, avg_metrics, filename_prefix=\"_Final_Combined_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "behavior_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
