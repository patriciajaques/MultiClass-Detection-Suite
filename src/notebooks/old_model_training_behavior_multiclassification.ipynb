{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/Users/patricia/Documents/code/python-code/behavior-detection/src\"\n",
    "os.chdir(path)  # Muda o diretório para o nível anterior (a raiz do projeto)\n",
    "print(os.getcwd())  # Verifique se agora está na raiz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from behavior.behavior_data_loader import BehaviorDataLoader\n",
    "\n",
    "data_path = '../data/new_logs_labels.csv'\n",
    "\n",
    "data_loader = BehaviorDataLoader(data_path, delimiter=';')\n",
    "data_loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores da coluna 'comportamento' antes da remoção:\", data_loader.data['comportamento'].value_counts())\n",
    "\n",
    "# Remove instances where 'comportamento' is '?'\n",
    "data_loader.remove_instances_with_value('comportamento', '?')\n",
    "\n",
    "print(\"\\nValores da coluna 'comportamento' depois da remoção:\", data_loader.data['comportamento'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader.get_data()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select a subset of the data only for testing purposes\n",
    "\n",
    "# Selecionar um subconjunto dos dados\n",
    "subset_data = data.sample(n=40, random_state=42)\n",
    "\n",
    "# Opcionalmente, redefina os índices\n",
    "subset_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessors.column_remover import ColumnRemover\n",
    "\n",
    "column_remover = ColumnRemover()\n",
    "columns_to_remove = ['id_log', 'aluno', 'grupo', 'num_dia', 'num_log']\n",
    "column_remover.set_columns_to_remove(columns_to_remove, data)\n",
    "cleaned_data = column_remover.remove_columns(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenche valores ausentes no DataFrame X com a string 'missing'.\n",
    "\n",
    "cleaned_data = cleaned_data.fillna('missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.preprocessors.data_preprocessor import DataPreprocessor\n",
    "X, y = DataPreprocessor.split_data(cleaned_data, \"comportamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding variables\n",
    "from behavior.behavior_data_preprocessor import BehaviorDataPreprocessor\n",
    "encoded_y = BehaviorDataPreprocessor.encode_y(y)\n",
    "preprocessor = BehaviorDataPreprocessor(X)\n",
    "preprocessor.preprocess()\n",
    "encoded_X = preprocessor.get_preprocessed_X()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance data\n",
    "from core.preprocessors.data_balancer import DataBalancer\n",
    "import pandas as pd\n",
    "encoded_y_series = pd.Series(encoded_y, name=\"comportamento\")\n",
    "data_balancer = DataBalancer()\n",
    "X_balanced, y_balanced = data_balancer.apply_smote(encoded_X, encoded_y_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(f\"Original dataset shape: {Counter(y)}\")\n",
    "print(f\"Resampled dataset shape: {Counter(y_balanced)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2  # 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(Counter(y_train))\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento dos Modelos usando Otimização Bayesiana (BayesSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.training.bayesian_optimization_training import BayesianOptimizationTraining\n",
    "cv = 10\n",
    "n_iter = 100\n",
    "n_jobs = 4  # Number of processors to be used in the execution: -1 to use all processors\n",
    "\n",
    "# Choose a scoring metric\n",
    "scoring_metric = 'roc_auc_ovr'  # Possible values: 'f1_macro', 'balanced_accuracy', 'roc_auc_ovr', etc.\n",
    "\n",
    "training = BayesianOptimizationTraining()\n",
    "\n",
    "trained_models = training.train_model(\n",
    "    X_train, y_train, n_iter=n_iter, cv=cv, scoring=scoring_metric, n_jobs=n_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.evaluation.evaluation import Evaluation  \n",
    "\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das características são as colunas\n",
    "class_metrics_results, avg_metrics_results = Evaluation.evaluate_all_models(trained_models, X_train, y_train, X_test, y_test, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração dos Relatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logging.report_formatter import ReportFormatter\n",
    "from core.logging.file_manager import FileManager\n",
    "\n",
    "directory = \"../output/\"\n",
    "\n",
    "# Gerar relatório textual a partir dos resultados de avaliação\n",
    "text_report = ReportFormatter.generate_text_report(class_metrics_results, avg_metrics_results)\n",
    "\n",
    "# Imprimir ou salvar o relatório\n",
    "FileManager.save_file_with_timestamp(text_report, \"bayesian_optimization_report.txt\", directory)\n",
    "\n",
    "# Gerar DataFrame detalhado dos relatórios por classe\n",
    "class_report_df = ReportFormatter.generate_class_report_dataframe(class_metrics_results)\n",
    "\n",
    "# Gerar DataFrame resumido dos relatórios de métricas médias\n",
    "avg_metrics_report_df = ReportFormatter.generate_avg_metrics_report_dataframe(avg_metrics_results)\n",
    "\n",
    "# Salvar os DataFrames como arquivos CSV, se necessário\n",
    "FileManager.save_csv_file_with_timestamp(class_report_df, \"class_report.csv\", directory)\n",
    "FileManager.save_csv_file_with_timestamp(avg_metrics_report_df, \"avg_metrics_report.csv\", directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando os modelos em arquivos para recuperação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logging.model_manager import ModelManager\n",
    "\n",
    "# Caminhos\n",
    "model_dir = \"../models/\"\n",
    "\n",
    "# Salvar todos os modelos\n",
    "saved_models = ModelManager.save_all_models(trained_models, model_dir)\n",
    "print(\"Modelos salvos:\", saved_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetos_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
