=====./behavior/behavior_data_loader.py=====
# behavior_data_loader.py

from typing import Optional
import pandas as pd
from core.preprocessors.data_loader import DataLoader

class BehaviorDataLoader(DataLoader):

    @staticmethod
    def get_feature_subset(data: pd.DataFrame, regex_pattern: str) -> pd.DataFrame:
        return data.filter(regex=regex_pattern)

    @staticmethod
    def get_behavior_features(data: pd.DataFrame) -> pd.DataFrame:
        return BehaviorDataLoader.get_feature_subset(data, '^comportamento|^ultimo_comportamento')

    @staticmethod
    def get_personality_features(data: pd.DataFrame) -> pd.DataFrame:
        personality_features = BehaviorDataLoader.get_feature_subset(data, '^traco_')
        return personality_features
    
    @staticmethod
    def get_personality_features_names(data: pd.DataFrame) -> list:
        return BehaviorDataLoader.get_personality_features(data).columns.tolist()

    @staticmethod
    def get_target_column(data: pd.DataFrame, target_name: Optional[str] = None) -> pd.Series:
        target = target_name or 'comportamento'
        if target not in data.columns:
            raise ValueError(f"The column '{target}' does not exist in the dataset.")
        return data[target]

    @staticmethod
    def get_data_info(data: pd.DataFrame) -> dict:
        return {
            'num_samples': len(data),
            'num_features': len(data.columns) - 1,
            'num_classes': data['comportamento'].nunique(),
            'class_distribution': data['comportamento'].value_counts().to_dict(),
            'missing_values': data.isnull().sum().to_dict()
        }=====./behavior/behavior_data_encoder.py=====
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from core.preprocessors.column_selector import ColumnSelector
from core.preprocessors.data_encoder import DataEncoder

class BehaviorDataEncoder(DataEncoder):
    def __init__(self, num_classes=5):
        super().__init__(num_classes)

    @staticmethod
    def encode_y(y):
        y_encoded = LabelEncoder().fit_transform(y)
        return y_encoded

    # def select_columns(self, X: pd.DataFrame):
    #     """ Seleciona colunas numéricas, nominais e ordinais
    #     para o conjunto de dados de comportamento.
    #     """
    #     self.column_selector = ColumnSelector(X, self.num_classes)
    #     behavior_columns = self.column_selector.get_columns_by_regex('^comportamento|^ultimo_comportamento')
    #     personality_columns = self.column_selector.get_columns_by_regex('^traco_')
    #     personality_columns = [col for col in personality_columns if not col.endswith('_cat')]
    #     all_columns = set(X.columns)
    #     selected_columns = set(behavior_columns + personality_columns)
    #     self.numerical_columns = list(all_columns - selected_columns)
    #     self.nominal_columns = behavior_columns + personality_columns
    #     self.ordinal_columns = []
    #     self.ordinal_categories = {}
=====./core/preprocessors/column_selector.py=====
import pandas as pd
from typing import List, Dict

class ColumnSelector:
    def __init__(self, data: pd.DataFrame, num_classes: int = 5):
        self.data = data
        self.num_classes = num_classes  # Max number of classes for a column to be considered nominal

    def get_numerical_columns(self) -> List[str]:
        return self.data.select_dtypes(include=['int64', 'float64']).columns.tolist()

    def get_nominal_columns(self) -> List[str]:
        condition = lambda col: (
            (self.data[col].dtype == 'object' or self.data[col].dtype == 'int64') and
            self.data[col].nunique() < self.num_classes
        )
        return [col for col in self.data.columns if condition(col)]

    def get_ordinal_columns(self) -> List[str]:
        # Assumes ordinal columns have "ordinal" in their name
        return [col for col in self.data.columns if 'ordinal' in col]

    def get_ordinal_categories(self) -> Dict[str, List]:
        ordinal_columns = self.get_ordinal_columns()
        return {col: self.data[col].unique().tolist() for col in ordinal_columns}

    def get_columns_by_regex(self, regex_pattern: str) -> List[str]:
        return self.data.filter(regex=regex_pattern).columns.tolist()
=====./core/preprocessors/data_loader.py=====
import pandas as pd

class DataLoader():
    """
    Class to load data from a CSV file in a dataframe.
    """

    @staticmethod
    def load_data(file_path: str, delimiter: str = ',', encoding: str = 'utf-8') -> None:
        """
        Load data from the CSV file into a DataFrame.
        """
        return pd.read_csv(file_path, delimiter=delimiter, encoding=encoding)
=====./core/preprocessors/data_encoder.py=====
import pandas as pd
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from core.preprocessors.column_selector import ColumnSelector

class DataEncoder():
    def __init__(self, num_classes: int):
        self.num_classes = num_classes
        self.column_selector = None
        self.column_transformer = None
        self.numerical_columns = None
        self.nominal_columns = None
        self.ordinal_columns = None
        self.ordinal_categories = None

    def initialize_encoder(self):
        transformers = []

        if self.numerical_columns:
            transformers.append(('num', MinMaxScaler(), self.numerical_columns))

        if self.nominal_columns:
            transformers.append(('nom', OneHotEncoder(sparse=False, handle_unknown='ignore'), self.nominal_columns))

        if self.ordinal_columns:
            categories = [self.ordinal_categories[col] for col in self.ordinal_columns]
            transformers.append(('ord', OrdinalEncoder(categories=categories), self.ordinal_columns))

        self.column_transformer = ColumnTransformer(transformers=transformers)

    def select_columns(self, X: pd.DataFrame):
        """ Seleciona colunas numéricas, nominais e ordinais
        baseado em algumas heurísticas genéricas definidas em ColumnSelector.
        """

        self.column_selector = ColumnSelector(X, self.num_classes)
        self.numerical_columns = self.column_selector.get_numerical_columns()
        self.nominal_columns = self.column_selector.get_nominal_columns()
        self.ordinal_columns = self.column_selector.get_ordinal_columns()
        self.ordinal_categories = self.column_selector.get_ordinal_categories()

    def fit(self, X: pd.DataFrame, y=None):
        self.select_columns(X)
        self.initialize_encoder()
        self.column_transformer.fit(X)
        return self

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        X_transformed = self.column_transformer.transform(X)
        feature_names = self.column_transformer.get_feature_names_out()
        if X_transformed.shape[1] != len(feature_names):
            raise ValueError(f"DataEncoder: Shape of transformed data is {X_transformed.shape}, but got {len(feature_names)} feature names.")
        return pd.DataFrame(X_transformed, columns=feature_names, index=X.index)

    def fit_transform(self, X: pd.DataFrame, y=None) -> pd.DataFrame:
        self.fit(X, y)
        return self.transform(X)

=====./core/preprocessors/data_balancer.py=====
import pandas as pd
from imblearn.over_sampling import SMOTE
from typing import Tuple

class DataBalancer:
    def __init__(self, random_state: int = 42):
        self.random_state = random_state

    def apply_smote(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:
        smote = SMOTE(random_state=self.random_state)
        X_resampled, y_resampled = smote.fit_resample(X, y)
        
        # Verifique se y é um pandas.Series ou numpy.ndarray
        if isinstance(y, pd.Series):
            y_name = y.name
        else:
            y_name = "target"
        
        return pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=y_name)=====./core/preprocessors/data_cleaner.py=====
class DataCleaner():
    
    @staticmethod
    def remove_instances_with_value(data, column: str, value: str):
        """
        Remove instances where the specified column has the specified value.

        Args:
            data (pd.DataFrame): The input data.
            column (str): The column to check.
            value (str): The value to remove.

        Returns:
            pd.DataFrame: The cleaned data.
        """
        return data[data[column] != value]
    
    @staticmethod
    def remove_columns(data, columns: list):
        """
        Remove the specified columns from the data.

        Args:
            data (pd.DataFrame): The input data.
            columns (list): The columns to remove.

        Returns:
            pd.DataFrame: The cleaned data.
        """
        return data.drop(columns=columns)
    =====./core/preprocessors/data_splitter.py=====
from typing import Tuple
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

class DataSplitter:
    @staticmethod
    def split_by_student_level(data, test_size=0.2, column_name='aluno'):
        unique_students = data[column_name].unique()
        train_students, test_students = train_test_split(unique_students, test_size=test_size, random_state=42)
        train_data = data[data[column_name].isin(train_students)]
        test_data = data[data[column_name].isin(test_students)]
        return train_data, test_data

    @staticmethod
    def split_by_stratified_student_level(data, test_size=0.2, column_name='aluno', target_column='comportamento', n_splits=10):
        unique_students = data[column_name].unique()
        stratified_split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)
        y = data.groupby(column_name)[target_column].first().loc[unique_students]
        for train_index, test_index in stratified_split.split(unique_students, y):
            train_students = unique_students[train_index]
            test_students = unique_students[test_index]
            break
        train_data = data[data[column_name].isin(train_students)]
        test_data = data[data[column_name].isin(test_students)]
        return train_data, test_data

    @staticmethod
    def split_data_stratified(data, test_size=0.2, target_column='comportamento', n_splits=1, random_state=42):
        stratified_split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)
        for train_index, test_index in stratified_split.split(data, data[target_column]):
            train_data = data.iloc[train_index]
            test_data = data.iloc[test_index]
            break
        return train_data, test_data

    @staticmethod
    def split_into_x_y(data: pd.DataFrame, target_column: str) -> Tuple[pd.DataFrame, pd.Series]:
        X = data.drop(columns=[target_column])
        y = data[target_column]
        return X, y=====./core/training/skopt_model_params.py=====
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb

from skopt.space import Real, Integer, Categorical

class SkoptModelParams:
    @staticmethod
    def get_models():
        return {
            'Logistic Regression': LogisticRegression(max_iter=5000),
            'Decision Tree': DecisionTreeClassifier(),
            'Random Forest': RandomForestClassifier(),
            'Gradient Boosting': GradientBoostingClassifier(),
            'SVM': SVC(probability=True),
            'KNN': KNeighborsClassifier(),
            'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')}

    @staticmethod
    def get_bayes_search_spaces():
        return {
            'Logistic Regression': SkoptModelParams._get_logistic_regression_space(),
            'Decision Tree': SkoptModelParams._get_decision_tree_space(),
            'Random Forest': SkoptModelParams._get_random_forest_space(),
            'Gradient Boosting': SkoptModelParams._get_gradient_boosting_space(),
            'SVM': SkoptModelParams._get_svm_space(),
            'KNN': SkoptModelParams._get_knn_space(),
            'XGBoost': SkoptModelParams._get_xgboost_space()
        }

    @staticmethod
    def _get_logistic_regression_space():
        return [
            {
                'classifier__penalty': Categorical(['l2']),
                'classifier__C': Real(0.01, 10, prior='log-uniform'),
                'classifier__solver': Categorical(['lbfgs', 'saga']),
                'classifier__max_iter': Integer(1000, 10000)
            },
            {
                'classifier__penalty': Categorical(['l1']),
                'classifier__C': Real(0.01, 10, prior='log-uniform'),
                'classifier__solver': Categorical(['liblinear', 'saga']),
                'classifier__max_iter': Integer(1000, 10000)
            }
        ]

    @staticmethod
    def _get_decision_tree_space():
        return {
            'classifier__max_depth': Categorical([None, 3, 5, 10, 20, 30]),
            'classifier__min_samples_split': Integer(2, 20),
            'classifier__min_samples_leaf': Integer(1, 10)
        }

    @staticmethod
    def _get_random_forest_space():
        return {
            'classifier__n_estimators': Integer(50, 300),
            'classifier__max_depth': Integer(3, 30),
            'classifier__min_samples_split': Integer(2, 20),
            'classifier__min_samples_leaf': Integer(1, 10),
            'classifier__max_features': Categorical(['sqrt', 'log2', None])
        }

    @staticmethod
    def _get_gradient_boosting_space():
        return {
            'classifier__n_estimators': Integer(50, 300),
            'classifier__learning_rate': Real(0.01, 0.2, prior='uniform'),
            'classifier__max_depth': Integer(3, 10),
            'classifier__subsample': Real(0.5, 1.0, prior='uniform'),
            'classifier__min_samples_split': Integer(2, 20),
            'classifier__min_samples_leaf': Integer(1, 10)
        }

    @staticmethod
    def _get_svm_space():
        return [
            {
                'classifier__C': Real(0.01, 10, prior='log-uniform'),
                'classifier__kernel': Categorical(['rbf']),
                'classifier__gamma': Real(1e-4, 1e-1, prior='log-uniform')
            },
            {
                'classifier__C': Real(0.01, 10, prior='log-uniform'),
                'classifier__kernel': Categorical(['linear']),
                'classifier__gamma': Categorical(['scale'])
            },
            {
                'classifier__C': Real(0.01, 10, prior='log-uniform'),
                'classifier__kernel': Categorical(['poly']),
                'classifier__gamma': Real(1e-4, 1e-1, prior='log-uniform'),
                'classifier__degree': Integer(2, 5)
            },
            {
                'classifier__C': Real(0.01, 10, prior='log-uniform'),
                'classifier__kernel': Categorical(['sigmoid']),
                'classifier__gamma': Real(1e-4, 1e-1, prior='log-uniform')
            }
        ]

    @staticmethod
    def _get_knn_space():
        return {
            'classifier__n_neighbors': Integer(3, 20),
            'classifier__weights': Categorical(['uniform', 'distance']),
            'classifier__metric': Categorical(['euclidean', 'manhattan', 'minkowski'])
        }

    @staticmethod
    def _get_xgboost_space():
        return {
            'classifier__n_estimators': Integer(50, 300),
            'classifier__learning_rate': Real(0.01, 0.2, prior='uniform'),
            'classifier__max_depth': Integer(3, 10),
            'classifier__subsample': Real(0.7, 1.0, prior='uniform'),
            'classifier__colsample_bytree': Real(0.7, 1.0, prior='uniform'),
            'classifier__reg_alpha': Real(0.0, 1.0, prior='uniform'),
            'classifier__reg_lambda': Real(0.0, 1.0, prior='uniform')
        }=====./core/training/model_training.py=====
# model_training.py

from abc import ABC, abstractmethod
from sklearn.pipeline import Pipeline
from core.training.skopt_model_params import SkoptModelParams
from core.feature_selection.feature_selection_factory import FeatureSelectionFactory
from typing import List, Optional, Dict, Any


class ModelTraining(ABC):
    def __init__(self):
        self.trained_models: Dict[str, Any] = {}

    def train_model(
        self,
        X_train,
        y_train,
        selected_models: Optional[List[str]] = None, # Lista de nomes de modelos a serem treinados.Se None, todos os modelos disponíveis serão utilizados.
        selected_selectors: Optional[List[str]] = None, # Lista de nomes de seletores a serem utilizados. Se None, todos os seletores disponíveis serão utilizados.
        n_iter: int = 50, # Número de iterações para otimização.
        cv: int = 5, # Número de folds para validação cruzada.
        scoring: str = 'balanced_accuracy', # Métrica de avaliação.
        n_jobs: int = -1 # Número de trabalhos paralelos.
    ) -> Dict[str, Any]: # Dicionário contendo os modelos treinados e seus resultados.
        """
        Treina modelos com diferentes seletores de características.
        """
        models = SkoptModelParams.get_models()
        available_selector_names = FeatureSelectionFactory.get_available_selectors()

        # Filtrar modelos
        models = self._filter_models(models, selected_models)

        # Filtrar seletores
        selector_names = self._filter_selectors(selected_selectors, available_selector_names)

        for model_name, model_config in models.items():
            for selector_name in selector_names:
                # Criar a instância do seletor diretamente dentro do loop
                selector_instance = FeatureSelectionFactory.create_selector(selector_name, X_train, y_train)
                selector = selector_instance.selector  # Acessar o seletor criado no construtor

                pipeline = self._create_pipeline(selector, model_config)

                # Obter o espaço de busca diretamente do selector_instance
                selector_search_space = selector_instance.get_search_space()

                self.optimize_model(
                    pipeline,
                    model_name,
                    selector_name,
                    X_train,
                    y_train,
                    n_iter,
                    cv,
                    scoring,
                    n_jobs,
                    selector_search_space  # Passar o espaço de busca
                )

        return self.trained_models

    @abstractmethod
    def optimize_model(
        self,
        pipeline,
        model_name: str,
        selector_name: str,
        X_train,
        y_train,
        n_iter: int,
        cv: int,
        scoring: str,
        n_jobs: int,
        selector_search_space: dict
    ):
        pass

    @staticmethod
    def _create_pipeline(selector, model_config) -> Pipeline:
        """
        Cria um pipeline com seleção de características e o classificador.

        Args:
            selector: Seletor de características.
            model_config: Configuração do modelo de classificação.

        Returns:
            Pipeline: Pipeline configurado.
        """
        return Pipeline([
            ('feature_selection', selector),
            ('classifier', model_config)
        ])

    def _filter_models(self, models: Dict[str, Any], selected_models: Optional[List[str]]) -> Dict[str, Any]:
        """
        Filtra os modelos baseados na lista de modelos selecionados.

        Args:
            models (Dict[str, Any]): Dicionário de modelos disponíveis.
            selected_models (Optional[List[str]]): Lista de modelos a serem utilizados.

        Returns:
            Dict[str, Any]: Dicionário filtrado de modelos.

        Raises:
            ValueError: Se algum modelo selecionado não for encontrado.
        """
        if selected_models is not None:
            filtered_models = {name: cfg for name, cfg in models.items() if name in selected_models}
            missing_models = set(selected_models) - set(filtered_models.keys())
            if missing_models:
                raise ValueError(f"Modelos não encontrados: {missing_models}")
            return filtered_models
        return models

    def _filter_selectors(self, selected_selectors: Optional[List[str]], available_selector_names: List[str]) -> List[str]:
        """
        Filtra os seletores baseados na lista de seletores selecionados.

        Args:
            selected_selectors (Optional[List[str]]): Lista de seletores a serem utilizados.
            available_selector_names (List[str]): Lista de seletores disponíveis.

        Returns:
            List[str]: Lista filtrada de seletores.

        Raises:
            ValueError: Se algum seletor selecionado não for encontrado.
        """
        if selected_selectors is not None:
            selector_names = [s for s in selected_selectors if s in available_selector_names]
            missing_selectors = set(selected_selectors) - set(selector_names)
            if missing_selectors:
                raise ValueError(f"Seletores não encontrados: {missing_selectors}")
            return selector_names
        return available_selector_names
=====./core/training/optuna_model_params.py=====
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
import xgboost as xgb

class OptunaModelParams:
    @staticmethod
    def get_models():
        return {
            'Logistic Regression': LogisticRegression(max_iter=5000),
            'Decision Tree': DecisionTreeClassifier(),
            'Random Forest': RandomForestClassifier(),
            'Gradient Boosting': GradientBoostingClassifier(),
            'SVM': SVC(probability=True),
            'KNN': KNeighborsClassifier(),
            'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
            # 'Naive Bayes': GaussianNB(),
            # 'MLP': MLPClassifier()
        }

    @staticmethod
    def suggest_hyperparameters(trial, model_name):
        """
        Sugere hiperparâmetros para o modelo especificado usando um trial do Optuna.
        """
        model_methods = {
            'Logistic Regression': OptunaModelParams._suggest_logistic_regression,
            'Decision Tree': OptunaModelParams._suggest_decision_tree,
            'Random Forest': OptunaModelParams._suggest_random_forest,
            'Gradient Boosting': OptunaModelParams._suggest_gradient_boosting,
            'SVM': OptunaModelParams._suggest_svm,
            'KNN': OptunaModelParams._suggest_knn,
            'XGBoost': OptunaModelParams._suggest_xgboost
            # 'Naive Bayes': OptunaModelParams._suggest_naive_bayes(trial),
            # 'MLP': OptunaModelParams._suggest_mlp(trial)
        }
        
        if model_name not in model_methods:
            raise ValueError(f"Modelo desconhecido: {model_name}")
        
        return model_methods[model_name](trial)

    @staticmethod
    def _suggest_logistic_regression(trial):
        penalty = trial.suggest_categorical('classifier__penalty', ['l1', 'l2'])
        C = trial.suggest_float('classifier__C', 0.01, 10, log=True)
        
        if penalty == 'l1':
            solver = trial.suggest_categorical('classifier__solver', ['liblinear', 'saga'])
        else:  # l2
            solver = trial.suggest_categorical('classifier__solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])
        
        max_iter = trial.suggest_int('classifier__max_iter', 1000, 10000)
        
        return {
            'classifier__penalty': penalty,
            'classifier__C': C,
            'classifier__solver': solver,
            'classifier__max_iter': max_iter
        }

    @staticmethod
    def _suggest_decision_tree(trial):
        return {
            'classifier__max_depth': trial.suggest_categorical('classifier__max_depth', [None, 3, 5, 10, 20, 30]),
            'classifier__min_samples_split': trial.suggest_int('classifier__min_samples_split', 2, 20),
            'classifier__min_samples_leaf': trial.suggest_int('classifier__min_samples_leaf', 1, 10)
        }

    @staticmethod
    def _suggest_random_forest(trial):
        return {
            'classifier__n_estimators': trial.suggest_int('classifier__n_estimators', 50, 300, step=50),
            'classifier__max_depth': trial.suggest_int('classifier__max_depth', 3, 30),
            'classifier__min_samples_split': trial.suggest_int('classifier__min_samples_split', 2, 20),
            'classifier__min_samples_leaf': trial.suggest_int('classifier__min_samples_leaf', 1, 10),
            'classifier__max_features': trial.suggest_categorical('classifier__max_features', ['sqrt', 'log2', None])
        }

    @staticmethod
    def _suggest_gradient_boosting(trial):
        return {
            'classifier__n_estimators': trial.suggest_int('classifier__n_estimators', 50, 300, step=50),
            'classifier__learning_rate': trial.suggest_float('classifier__learning_rate', 0.01, 0.2),
            'classifier__max_depth': trial.suggest_int('classifier__max_depth', 3, 10),
            'classifier__subsample': trial.suggest_float('classifier__subsample', 0.5, 1.0),
            'classifier__min_samples_split': trial.suggest_int('classifier__min_samples_split', 2, 20),
            'classifier__min_samples_leaf': trial.suggest_int('classifier__min_samples_leaf', 1, 10)
        }

    @staticmethod
    def _suggest_svm(trial):
        params = {
            'classifier__C': trial.suggest_float('classifier__C', 0.01, 10, log=True),
            'classifier__kernel': trial.suggest_categorical('classifier__kernel', ['rbf', 'linear', 'poly', 'sigmoid'])
        }
        if params['classifier__kernel'] in ['rbf', 'poly', 'sigmoid']:
            params['classifier__gamma'] = trial.suggest_float('classifier__gamma', 1e-4, 1e-1, log=True)
        if params['classifier__kernel'] == 'poly':
            params['classifier__degree'] = trial.suggest_int('classifier__degree', 2, 5)
        return params

    @staticmethod
    def _suggest_knn(trial):
        return {
            'classifier__n_neighbors': trial.suggest_int('classifier__n_neighbors', 3, 20),
            'classifier__weights': trial.suggest_categorical('classifier__weights', ['uniform', 'distance']),
            'classifier__metric': trial.suggest_categorical('classifier__metric', ['euclidean', 'manhattan', 'minkowski'])
        }

    @staticmethod
    def _suggest_xgboost(trial):
        return {
            'classifier__n_estimators': trial.suggest_int('classifier__n_estimators', 50, 300, step=50),
            'classifier__learning_rate': trial.suggest_float('classifier__learning_rate', 0.01, 0.2),
            'classifier__max_depth': trial.suggest_int('classifier__max_depth', 3, 10),
            'classifier__subsample': trial.suggest_float('classifier__subsample', 0.7, 1.0),
            'classifier__colsample_bytree': trial.suggest_float('classifier__colsample_bytree', 0.7, 1.0),
            'classifier__reg_alpha': trial.suggest_float('classifier__reg_alpha', 0.0, 1.0),
            'classifier__reg_lambda': trial.suggest_float('classifier__reg_lambda', 0.0, 1.0)
        }=====./core/training/optuna_bayesian_optimization_training.py=====
import optuna
from optuna.samplers import TPESampler
from sklearn.model_selection import cross_val_score
from core.training.model_training import ModelTraining
from core.training.optuna_model_params import OptunaModelParams
from core.logging.logger_config import LoggerConfig
import logging
from time import time
import pandas as pd

class OptunaBayesianOptimizationTraining(ModelTraining):
    def __init__(self):
        super().__init__()
        # Configurar um logger nomeado para a otimização bayesiana com Optuna
        LoggerConfig.configure_log_file(
            file_main_name='optuna_bayesian_optimization',
            log_extension=".log",
            logger_name='optuna_bayesian_optimization'
        )
        self.logger = logging.getLogger('optuna_bayesian_optimization')

    def optimize_model(self, pipeline, model_name, selector_name, X_train, y_train, n_trials, cv, scoring, n_jobs=-1, selector_search_space=None):
        self.logger.info(f"Training and evaluating {model_name} with Optuna Bayesian Optimization and {selector_name}")
        print(f"Training and evaluating {model_name} with Optuna Bayesian Optimization and {selector_name}")

        def objective(trial):
            try:
                model_hyperparams = OptunaModelParams.suggest_hyperparameters(trial, model_name)
                
                # Sugerir hiperparâmetros para o seletor de features
                selector_hyperparams = {}
                for param, values in selector_search_space.items():
                    if isinstance(values, list) and isinstance(values[0], int):
                        selector_hyperparams[param] = trial.suggest_int(param, min(values), max(values))
                    elif isinstance(values, list) and isinstance(values[0], float):
                        selector_hyperparams[param] = trial.suggest_float(param, min(values), max(values))
                    elif isinstance(values, list) and isinstance(values[0], str):
                        selector_hyperparams[param] = trial.suggest_categorical(param, values)
                    else:
                        selector_hyperparams[param] = trial.suggest_categorical(param, values)
                
                # Combinar os hiperparâmetros do modelo e do seletor
                hyperparams = {**model_hyperparams, **selector_hyperparams}
                
                pipeline.set_params(**hyperparams)
                
                score = cross_val_score(
                    estimator=pipeline,
                    X=X_train,
                    y=y_train,
                    scoring=scoring,
                    cv=cv,
                    n_jobs=n_jobs
                ).mean()
                
                return score
            except Exception as e:
                self.logger.warning(f"Trial failed with error: {str(e)}")
                return float('-inf')  # Retorna um valor muito baixo para indicar que o trial falhou
        
        # Criar um estudo do Optuna
        study = optuna.create_study(direction='maximize', sampler=TPESampler())
        
        # Iniciar o tempo de otimização
        start_time = time()
        study.optimize(objective, n_trials=n_trials)
        total_time = time() - start_time

        # Registrar informações resumidas sobre o estudo
        self.logger.info(f"Optuna Optimization completed in {total_time:.2f} seconds")
        self.logger.info(f"Number of trials: {n_trials}")
        self.logger.info(f"Best trial index: {study.best_trial.number}")
        self.logger.info(f"Best score: {study.best_trial.value}")
        self.logger.info(f"Best hyperparameters: {study.best_trial.params}")

        print(f"---Optuna Bayesian Optimization---")
        print(f"Total time: {total_time:.2f} seconds")
        print(f"Number of trials: {n_trials}")
        print(f"Best trial index: {study.best_trial.number}")
        print(f"Best score: {study.best_trial.value}")
        print(f"Best hyperparameters: {study.best_trial.params}")

        # # Salvar todos os resultados dos trials em um DataFrame
        # trials_df = study.trials_dataframe()
        # trials_csv_path = f"optuna_trials_{model_name}_{selector_name}.csv"
        # trials_df.to_csv(trials_csv_path, index=False)
        # self.logger.info(f"All trial results saved to {trials_csv_path}")
        # print(f"All trial results saved to {trials_csv_path}")

        # Atualizar o pipeline com os melhores hiperparâmetros
        pipeline.set_params(**study.best_trial.params)
        
        # Treinar o modelo final com os melhores hiperparâmetros
        pipeline.fit(X_train, y_train)
        
        # Armazenar os resultados
        self.trained_models[f"{model_name}_{selector_name}"] = {
            'model': pipeline,
            'training_type': "Optuna Bayesian Optimization",
            'hyperparameters': study.best_trial.params,
            'cv_result': study.best_trial.value,
            'optimization_time_seconds': total_time
        }

        # Log final do melhor resultado
        self.logger.info(f"Optuna Optimization Best Result for {model_name} with {selector_name}: {study.best_trial.value}")
        print(f"Optuna Optimization Best Result for {model_name} with {selector_name}: {study.best_trial.value}")
=====./core/training/skopt_bayesian_optimization_training.py=====
# bayesian_optimization_training.py

from skopt import BayesSearchCV
from core.training.model_training import ModelTraining
from core.training.skopt_model_params import SkoptModelParams
from core.logging.logger_config import LoggerConfig
import logging

class SkoptBayesianOptimizationTraining(ModelTraining):
    def __init__(self):
        super().__init__()
        LoggerConfig.configure_log_file('bayesian_optimization', '.log')

    def optimize_model(self, pipeline, model_name, selector_name, X_train, y_train, n_iter, cv, scoring, n_jobs=-1, selector_search_space=None):
        logging.info(f"Training and evaluating {model_name} with Bayesian Optimization and {selector_name}")
        print(f"Training and evaluating {model_name} with Bayesian Optimization and {selector_name}")

        # Obter o espaço de busca específico do modelo
        search_space_model = SkoptModelParams.get_bayes_search_spaces().get(model_name, {})
        # Obter o espaço de busca específico do seletor (já passado como parâmetro)
        search_space_selector = selector_search_space

        # Combinar os espaços de busca do modelo e do seletor
        if isinstance(search_space_model, list):
            for subspace in search_space_model:
                subspace.update(search_space_selector)
        else:
            search_space_model.update(search_space_selector)

        logging.info(f"Search space for {model_name} with selector {selector_name}: {search_space_model}")

        best_model, best_result, opt = self._execute_bayesian_optimization(
            pipeline,
            search_space_model,
            X_train,
            y_train,
            n_iter,
            cv,
            scoring,
            n_jobs
        )

        logging.info(f"Bayesian optimization results: Best result: {best_result}, "
                     f"Average cross-validation result: {opt.cv_results_['mean_test_score'][opt.best_index_]}")
        
        self._store_model_results(model_name, selector_name, best_model, best_result)

    def _execute_bayesian_optimization(self, pipeline, space, X_train, y_train, n_iter=50, cv=5, scoring='balanced_accuracy', n_jobs=-1):
        search = BayesSearchCV(
            pipeline,
            search_spaces=space,
            n_iter=n_iter,
            cv=cv,
            scoring=scoring,
            n_jobs=n_jobs,
            random_state=42,
            verbose=3
        )

        search.fit(X_train, y_train, callback=LoggerConfig.log_results)
        return search.best_estimator_, search.best_score_, search

    def _store_model_results(self, model_name, selector_name, best_model, best_result):
        self.trained_models[f"{model_name}_{selector_name}"] = {
            'model': best_model,
            'training_type': "Bayesian Optimization",
            'hyperparameters': best_model.get_params(),
            'cv_result': best_result
        }
        logging.info(f"Bayesian Optimization Best Result for {model_name} with {selector_name}: {best_result}")
        print(f"Bayesian Optimization Best Result for {model_name} with {selector_name}: {best_result}")
=====./core/feature_selection/mi_feature_selector.py=====
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import SelectKBest
from core.feature_selection.base_feature_selector import BaseFeatureSelector

class MutualInformationFeatureSelector(BaseFeatureSelector):
    def __init__(self, X_train, y_train, k=10):
        super().__init__(X_train, y_train, k=k)

    def _create_selector(self, k=10):
        selector = SelectKBest(mutual_info_classif, k=k)
        selector.fit(self.X_train, self.y_train)
        return selector

    def get_search_space(self):
        return {'feature_selection__k': [5, 10, 20, 30, 40, 50, 'all']}=====./core/feature_selection/base_feature_selector.py=====
from abc import ABC, abstractmethod

class BaseFeatureSelector(ABC):
    def __init__(self, X_train, y_train=None, **kwargs):
        self.X_train = X_train
        self.y_train = y_train
        self.selector = self._create_selector(**kwargs)
    
    @abstractmethod
    def _create_selector(self, **kwargs):
        """
        Método abstrato para criar o seletor de características.
        Deve ser implementado por todas as subclasses.
        """
        pass

    @abstractmethod
    def get_search_space(self):
        """
        Método abstrato para retornar o espaço de busca de hiperparâmetros.
        Deve ser implementado por todas as subclasses.
        """
        pass
=====./core/feature_selection/feature_selection_factory.py=====
import numpy as np

from core.feature_selection.pca_feature_selector import PCAFeatureSelector
from core.feature_selection.random_forest_feature_selector import RandomForestFeatureSelector
from core.feature_selection.rfe_feature_selector import RFEFeatureSelector
from core.feature_selection.mi_feature_selector import MutualInformationFeatureSelector

class FeatureSelectionFactory:
    @staticmethod
    def create_selector(method, X_train, y_train=None, **kwargs):
        if method == 'rfe':
            selector = RFEFeatureSelector(X_train, y_train, **kwargs)
        elif method == 'pca':
            selector = PCAFeatureSelector(X_train, **kwargs)
        elif method == 'rf':
            selector = RandomForestFeatureSelector(X_train, y_train)
        elif method == 'mi':
            selector = MutualInformationFeatureSelector(X_train, y_train, **kwargs)
        else:
            raise ValueError(f"Método desconhecido: {method}")
        return selector

    @staticmethod
    def get_available_selectors():
        """
        Retorna uma lista dos métodos de seleção de características disponíveis.
        """
        return ['rfe', 'pca', 'rf', 'mi']

    @staticmethod
    def extract_selected_features(pipeline, feature_names):
        """
        Extrai as características selecionadas pelo seletor de características no pipeline.

        Args:
            pipeline: Pipeline treinado.
            feature_names: Lista de nomes das características originais.

        Returns:
            List: Lista de características selecionadas.
        """
        selector = pipeline.named_steps['feature_selection']

        if hasattr(selector, 'get_support'):
            mask = selector.get_support()
            selected_features = np.array(feature_names)[mask]
        elif hasattr(selector, 'transform'):
            # Para métodos como PCA que transformam as características
            transformed = selector.transform(np.identity(len(feature_names)))
            # Retornar os componentes principais como nomes
            selected_features = [f'PC{i+1}' for i in range(transformed.shape[1])]
        else:
            raise ValueError("O seletor não tem métodos para extrair características.")

        return selected_features
=====./core/feature_selection/random_forest_feature_selector.py=====
import numpy as np
import logging
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel

from core.feature_selection.base_feature_selector import BaseFeatureSelector

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RandomForestFeatureSelector(BaseFeatureSelector):
    def __init__(self, X_train, y_train, max_features=None):
        self.max_features = max_features
        super().__init__(X_train, y_train)

    def _create_selector(self):
        n_features = self.X_train.shape[1]
        estimator = RandomForestClassifier(n_estimators=100, random_state=42)
        estimator.fit(self.X_train, self.y_train)
        
        # Se max_features não for especificado, use metade das features
        if self.max_features is None or self.max_features == 'auto':
            self.max_features = max(1, n_features // 2)
        elif isinstance(self.max_features, float):
            self.max_features = max(1, int(self.max_features * n_features))
        
        selector = SelectFromModel(estimator, max_features=self.max_features, prefit=True)
        
        selected_features = selector.get_support().sum()
        logger.info(f"Selected {selected_features} features")
        
        return selector

    def get_search_space(self):
        n_features = self.X_train.shape[1]
        max_features_range = list(range(1, n_features + 1))
        return {
            'feature_selection__max_features': max_features_range,
            'feature_selection__threshold': ['mean', 'median', '0.5*mean', '1.5*mean']
        }

    def set_params(self, **params):
        if 'max_features' in params:
            self.max_features = int(params['max_features'])
            self.selector.max_features = self.max_features
        
        if 'threshold' in params:
            if isinstance(params['threshold'], str):
                estimator = self.selector.estimator
                feature_importances = estimator.feature_importances_
                if params['threshold'] == 'mean':
                    threshold = np.mean(feature_importances)
                elif params['threshold'] == 'median':
                    threshold = np.median(feature_importances)
                elif params['threshold'] == '0.5*mean':
                    threshold = 0.5 * np.mean(feature_importances)
                elif params['threshold'] == '1.5*mean':
                    threshold = 1.5 * np.mean(feature_importances)
                self.selector.threshold = threshold
            else:
                self.selector.threshold = params['threshold']
        return self=====./core/feature_selection/rfe_feature_selector.py=====
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE

from core.feature_selection.base_feature_selector import BaseFeatureSelector

class RFEFeatureSelector(BaseFeatureSelector):
    def __init__(self, X_train, y_train, n_features_to_select=10):
        super().__init__(X_train, y_train, n_features_to_select=n_features_to_select)

    def _create_selector(self, n_features_to_select=10):
        n_features = self.X_train.shape[1]
        estimator = RandomForestClassifier(n_estimators=100, random_state=42)
        selector = RFE(estimator, n_features_to_select=min(n_features_to_select, n_features))
        return selector

    def get_search_space(cls):
        return {'feature_selection__n_features_to_select': [1, 5, 10, 20, 30, 40, 50]}=====./core/feature_selection/pca_feature_selector.py=====
from sklearn.decomposition import PCA

from core.feature_selection.base_feature_selector import BaseFeatureSelector

class PCAFeatureSelector(BaseFeatureSelector):
    def __init__(self, X_train, n_components=5):
        super().__init__(X_train, n_components=n_components)

    def _create_selector(self, n_components=5):
        n_features = self.X_train.shape[1]
        selector = PCA(n_components=min(n_components, n_features))
        return selector

    def get_search_space(self):
        return {'feature_selection__n_components': [1, 5, 10, 20, 30, 40, 50, 75, 100, 125, 150, 175, 200]}=====./core/exploration/data_exploration.py=====
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from typing import Union, List, Dict

class DataExploration:

    @staticmethod
    def has_few_classes(column: pd.Series, num_classes: int = 5) -> bool:
        return column.nunique() < num_classes

    @staticmethod
    def inspect_dataframe(df: Union[pd.DataFrame, pd.Series]) -> None:
        print('Primeiras linhas do DataFrame:')
        print(df.head())
        print('\nInformações sobre o DataFrame:')
        print(df.info())

    @staticmethod
    def inspect_numeric_data(df: pd.DataFrame) -> None:
        print('Estatísticas descritivas do DataFrame:')
        print(df.select_dtypes(include=['float64', 'int64']).describe())

    @staticmethod
    def inspect_categorical_data(df: Union[pd.DataFrame, pd.Series]) -> None:
        print('Número de instâncias por classe:')
        if isinstance(df, pd.Series):
            DataExploration._print_series_categories(df)
        else:
            for i, column in enumerate(df.columns, start=1):
                print(f"({i}) {column}:")
                DataExploration._print_series_categories(df[column])

    @staticmethod
    def _print_series_categories(series: pd.Series) -> None:
        if series.nunique() < 10:
            for category in series.unique():
                count = (series == category).sum()
                print(f"    Categoria: {category}, Contagem: {count}")
        else:
            print(f"    Número de categorias: {series.nunique()}")

    @staticmethod
    def create_metadata_file(df: pd.DataFrame, file_path: str = 'data/metadata.csv') -> None:
        metadata = df.dtypes
        metadata.to_csv(file_path, header=['data_type'], sep=';')
        print(f'Metadados salvos em {file_path}')

    @staticmethod
    def visualize_histogram(df: pd.DataFrame, num_bins: int = 10, x_range: tuple = (0, 0), y_range: tuple = (0, 0)) -> None:
        axes = df.hist(bins=num_bins, figsize=(20, 15))
        for ax in axes.flatten():
            if x_range != (0, 0):
                ax.set_xlim(x_range)
            if y_range != (0, 0):
                ax.set_ylim(y_range)
        plt.show()

    @staticmethod
    def visualize_correlation_numeric(df: pd.DataFrame) -> None:
        corr = df.corr()
        plt.figure(figsize=(12, 10))
        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
        plt.title('Matriz de Correlação')
        plt.show()

    @staticmethod
    def visualize_correlation_categorical(X: pd.DataFrame, y: pd.DataFrame, output_dir: str = '../output/heatmaps', batch_size: int = 25) -> None:
        os.makedirs(output_dir, exist_ok=True)
        X_cat = X.select_dtypes(include=['object', 'category'])
        y_cat = y.select_dtypes(include=['object', 'category'])

        total_plots = len(X_cat.columns) * len(y_cat.columns)
        batches = (total_plots // batch_size) + (total_plots % batch_size != 0)

        for batch in range(batches):
            fig, axs = plt.subplots(min(batch_size, total_plots - batch * batch_size), 1, figsize=(5, min(batch_size, total_plots - batch * batch_size) * 5))
            axs = [axs] if total_plots - batch * batch_size == 1 else axs
            for k, (i, j) in enumerate([(i, j) for i in range(len(X_cat.columns)) for j in range(len(y_cat.columns))][batch * batch_size:(batch + 1) * batch_size]):
                col_x, col_y = X_cat.columns[i], y_cat.columns[j]
                contingency_table = pd.crosstab(index=X_cat[col_x], columns=y_cat[col_y])
                sns.heatmap(contingency_table, annot=True, cmap='coolwarm', fmt=".2f", ax=axs[k])
                axs[k].set_title(f'{col_x} e {col_y}')
            
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, f'heatmap_batch_{batch + 1}.png'))
            plt.close(fig)

    @staticmethod
    def visualize_feature_target_correlation(X: pd.DataFrame, y: pd.Series, top_n: int = 10, figsize: tuple = (12, 8)) -> None:
        """
        Visualiza a correlação entre as features numéricas de X e o target numérico y.

        Args:
            X (pd.DataFrame): DataFrame contendo as features.
            y (pd.Series): Series contendo o target numérico.
            top_n (int): Número de features com maior correlação absoluta a serem exibidas.
            figsize (tuple): Tamanho da figura para o plot.

        Returns:
            None
        """
        if not pd.api.types.is_numeric_dtype(y):
            raise ValueError("O target (y) deve ser numérico para calcular correlações.")

        # Selecionar apenas colunas numéricas de X
        X_numeric = X.select_dtypes(include=['float64', 'int64'])

        # Calcular correlações
        correlations = X_numeric.apply(lambda x: x.corr(y) if pd.api.types.is_numeric_dtype(x) else 0)

        # Ordenar correlações por valor absoluto e selecionar top_n
        top_correlations = correlations.abs().nlargest(top_n)

        # Criar um DataFrame com as correlações para facilitar o plotting
        corr_df = pd.DataFrame({'feature': top_correlations.index, 'correlation': correlations[top_correlations.index]})
        corr_df = corr_df.sort_values('correlation', key=abs, ascending=True)

        # Plotar
        plt.figure(figsize=figsize)
        ax = sns.barplot(x='correlation', y='feature', data=corr_df, orient='h')
        ax.axvline(x=0, color='black', linewidth=0.5)
        plt.title(f'Top {top_n} Correlações entre Features e Target')
        plt.xlabel('Correlação')
        plt.ylabel('Feature')
        
        # Adicionar valores de correlação nas barras
        for i, v in enumerate(corr_df['correlation']):
            ax.text(v, i, f'{v:.2f}', va='center', fontweight='bold')

        plt.tight_layout()
        plt.show()

    @staticmethod
    def get_feature_target_correlation(X: pd.DataFrame, y: pd.Series) -> pd.Series:
        """
        Calcula a correlação entre as features numéricas de X e o target numérico y.

        Args:
            X (pd.DataFrame): DataFrame contendo as features.
            y (pd.Series): Series contendo o target numérico.

        Returns:
            pd.Series: Series contendo as correlações ordenadas por valor absoluto.
        """
        if not pd.api.types.is_numeric_dtype(y):
            raise ValueError("O target (y) deve ser numérico para calcular correlações.")

        X_numeric = X.select_dtypes(include=['float64', 'int64'])
        correlations = X_numeric.apply(lambda x: x.corr(y) if pd.api.types.is_numeric_dtype(x) else 0)
        return correlations.sort_values(key=abs, ascending=False)

=====./core/evaluation/evaluation.py=====
import numpy as np
import pandas as pd
from core.feature_selection.feature_selection_factory import FeatureSelectionFactory

from sklearn.metrics import (
    average_precision_score,
    classification_report,
    balanced_accuracy_score,
    cohen_kappa_score,
    confusion_matrix
)

class Evaluation:
    @staticmethod
    def evaluate_all_models(trained_models, X_train, y_train, X_test, y_test, feature_names=None):
        class_metrics_results = {}
        avg_metrics_results = {}

        for model_name, model_info in trained_models.items():
            model = model_info['model']
            cv_score = model_info['cv_result']

            train_results = Evaluation._evaluate_model(model, X_train, y_train, feature_names)
            test_results = Evaluation._evaluate_model(model, X_test, y_test, feature_names)

            class_metrics_results[model_name] = {
                'train_class_report': train_results['class_report'],
                'train_conf_matrix': train_results['conf_matrix'],
                'test_class_report': test_results['class_report'],
                'test_conf_matrix': test_results['conf_matrix'],
                'selected_features': test_results['selected_features']
            }

            avg_metrics_results[model_name] = {
                'cv_report': cv_score,
                'train_avg_metrics': train_results['avg_metrics'],
                'test_avg_metrics': test_results['avg_metrics'],
                'training_type': model_info['training_type'],
                'hyperparameters': model_info['hyperparameters']
            }

        return class_metrics_results, avg_metrics_results

    @staticmethod
    def _evaluate_model(model, X, y, feature_names=None):
        y_pred = model.predict(X)
        y_prob = model.predict_proba(X)

        class_report = Evaluation._generate_class_report(y, y_pred)
        avg_metrics = Evaluation._generate_avg_metrics(y, y_pred, y_prob)
        conf_matrix = Evaluation._generate_conf_matrix(y, y_pred)
        selected_features = Evaluation._extract_selected_features(model, feature_names)

        return {
            'class_report': class_report,
            'avg_metrics': avg_metrics,
            'conf_matrix': conf_matrix,
            'selected_features': selected_features
        }

    @staticmethod
    def _generate_class_report(y_true, y_pred):
        class_report = classification_report(y_true, y_pred, output_dict=True)
        class_report_df = pd.DataFrame(class_report).transpose().round(2)
        return class_report_df.drop(['accuracy', 'macro avg', 'weighted avg'])

    @staticmethod
    def _generate_avg_metrics(y_true, y_pred, y_prob):
        avg_metrics = {
            'balanced_accuracy': {'f1-score': balanced_accuracy_score(y_true, y_pred)},
            'kappa': {'f1-score': cohen_kappa_score(y_true, y_pred)},
            'auc_pr_macro': {'f1-score': Evaluation._calculate_auc_pr(y_true, y_prob)}
        }
        avg_metrics_df = pd.DataFrame(avg_metrics).transpose().round(2)

        class_report = classification_report(y_true, y_pred, output_dict=True)
        class_report_df = pd.DataFrame(class_report).transpose().round(2)
        additional_metrics = class_report_df.loc[['accuracy', 'macro avg', 'weighted avg']]

        return pd.concat([avg_metrics_df, additional_metrics])

    @staticmethod
    def _generate_conf_matrix(y_true, y_pred):
        conf_matrix = confusion_matrix(y_true, y_pred)
        classes = sorted(set(y_true))
        return pd.DataFrame(
            conf_matrix,
            index=[f'Actual {cls}' for cls in classes],
            columns=[f'Predicted {cls}' for cls in classes]
        )

    @staticmethod
    def _extract_selected_features(model, feature_names):
        if feature_names is not None:
            return FeatureSelectionFactory.extract_selected_features(model, feature_names)
        return None

    @staticmethod
    def _calculate_auc_pr(y_true, y_prob):
        auc_pr = [
            average_precision_score(y_true == i, y_prob[:, i])
            for i in range(len(np.unique(y_true)))
        ]
        return np.mean(auc_pr)=====./core/logging/report_formatter.py=====
import pandas as pd

class ReportFormatter:
    @staticmethod
    def generate_text_report(class_metrics_reports, avg_metrics_reports):
        report_output = ""
        for model_name, model_info in class_metrics_reports.items():
            avg_info = avg_metrics_reports[model_name]
            report_output += ReportFormatter._format_model_report(model_name, model_info, avg_info)
        return report_output

    @staticmethod
    def _format_model_report(model_name, model_info, avg_info):
        report = (f"\nEvaluating {model_name} with {avg_info['training_type']}:\n"
                  f"Hyperparameters: {avg_info['hyperparameters']}\n")
        
        if 'selected_features' in model_info:
            report += f"\nSelected Features: {', '.join(str(feature) for feature in model_info['selected_features'])}\n"
        
        report += ReportFormatter._format_set_report("Train", model_info, avg_info)
        report += ReportFormatter._format_set_report("Test", model_info, avg_info)
        return report

    @staticmethod
    def _format_set_report(set_name, model_info, avg_info):
        report = f"\n{set_name} set class report:\n"
        report += ReportFormatter._format_classification_report(model_info[f'{set_name.lower()}_class_report'])
        report += f"\n{set_name} set average metrics:\n"
        report += ReportFormatter._format_classification_report(avg_info[f'{set_name.lower()}_avg_metrics'])
        report += f"\n{set_name} set confusion matrix:\n"
        report += model_info[f'{set_name.lower()}_conf_matrix'].to_string() + "\n"
        return report

    @staticmethod
    def _format_classification_report(report_df):
        output = ""
        for index, row in report_df.iterrows():
            if index in ['accuracy', 'balanced_accuracy']:
                output += f"{index.capitalize()}: {row['f1-score']}\n"
            else:
                output += (f"Class {index} - Precision: {row['precision']}, Recall: {row['recall']}, "
                           f"F1-Score: {row['f1-score']}, Support: {row['support']}\n")
        return output

    @staticmethod
    def generate_class_report_dataframe(class_metrics_reports):
        return pd.concat([
            ReportFormatter._prepare_model_report(model_name, model_info)
            for model_name, model_info in class_metrics_reports.items()
        ])

    @staticmethod
    def _prepare_model_report(model_name, model_info):
        train_report = model_info['train_class_report'].add_suffix('-train')
        test_report = model_info['test_class_report'].add_suffix('-test')
        combined_report = train_report.join(test_report)
        combined_report['Model'] = model_name
        return combined_report.reset_index().rename(columns={'index': 'Metric'})

    @staticmethod
    def generate_avg_metrics_report_dataframe(avg_metrics_reports):
        return pd.concat([
            ReportFormatter._prepare_avg_metrics_report(model_name, model_info)
            for model_name, model_info in avg_metrics_reports.items()
        ])

    @staticmethod
    def _prepare_avg_metrics_report(model_name, model_info):
        train_metrics = model_info['train_avg_metrics'].add_suffix('-train')
        test_metrics = model_info['test_avg_metrics'].add_suffix('-test')
        combined_report = train_metrics.join(test_metrics)
        combined_report['Model'] = model_name
        return combined_report.reset_index().rename(columns={'index': 'Metric'})=====./core/logging/logger_config.py=====
import logging
import os
from datetime import datetime
from pathlib import Path

class LoggerConfig:
    @staticmethod
    def configure_log_file(file_main_name='bayesian_optimization', log_extension=".log", logger_name=None):
        """
        Configura um arquivo de log. Pode configurar o logger raiz ou um logger nomeado.

        Args:
            file_main_name (str): Nome base para o arquivo de log.
            log_extension (str): Extensão do arquivo de log.
            logger_name (str, optional): Nome do logger a ser configurado. Se None, configura o logger raiz.
        """
        output_dir = LoggerConfig._get_output_directory()
        log_filename = LoggerConfig._generate_log_filename(file_main_name, log_extension)
        log_file_path = os.path.join(output_dir, log_filename)
        
        if logger_name:
            logger = logging.getLogger(logger_name)
            logger.setLevel(logging.DEBUG)  # Captura todos os níveis de log
            
            # Evita adicionar múltiplos handlers se já existirem
            if not logger.handlers:
                # Handler para arquivo com nível DEBUG
                fh = logging.FileHandler(log_file_path)
                fh.setLevel(logging.DEBUG)
                
                # Handler para console com nível INFO
                ch = logging.StreamHandler()
                ch.setLevel(logging.INFO)
                
                # Formatação dos logs
                formatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s')
                fh.setFormatter(formatter)
                ch.setFormatter(formatter)
                
                # Adiciona os handlers ao logger
                logger.addHandler(fh)
                logger.addHandler(ch)
        else:
            # Configura o logger raiz se ainda não estiver configurado
            root_logger = logging.getLogger()
            if not root_logger.handlers:
                logging.basicConfig(
                    filename=log_file_path,
                    level=logging.INFO,
                    filemode='w',
                    format='%(asctime)s:%(levelname)s:%(message)s'
                )

    @staticmethod
    def _get_output_directory():
        """
        Obtém o diretório de saída para armazenar os arquivos de log.

        Returns:
            str: Caminho do diretório de saída.
        """
        # Obtém o diretório atual onde o arquivo Python está localizado
        current_dir = Path(__file__).resolve()
        
        # Encontra a raiz do projeto subindo até encontrar a pasta 'src'
        src_dir = current_dir
        while src_dir.name != 'behavior-detection' and src_dir.parent != src_dir:
            src_dir = src_dir.parent

        # Verifica se a pasta 'src' foi encontrada
        if src_dir.name != 'behavior-detection':
            raise FileNotFoundError("Diretório 'src' não encontrado na estrutura de diretórios.")
        
        # Define o diretório de saída dentro da pasta src
        output_dir = src_dir / 'output'
        os.makedirs(output_dir, exist_ok=True)
        return output_dir

    @staticmethod
    def _generate_log_filename(file_main_name, log_extension):
        """
        Gera um nome de arquivo para o log baseado no timestamp atual.

        Args:
            file_main_name (str): Nome base para o arquivo de log.
            log_extension (str): Extensão do arquivo de log.

        Returns:
            str: Nome completo do arquivo de log.
        """
        return datetime.now().strftime(f'{file_main_name}_%Y%m%d_%H%M{log_extension}')

    @staticmethod
    def log_results(result):
        """
        Registra os resultados de uma iteração de otimização.

        Args:
            result: Resultado da iteração (deve ter atributos x_iters e func_vals).
        """
        if hasattr(result, 'x_iters') and hasattr(result, 'func_vals') and result.x_iters:
            score = abs(result.func_vals[-1])  # Use valor absoluto para simplificar
            logging.info(f"Iteration {len(result.x_iters)}: tested parameters: {result.x_iters[-1]}, score: {score}")

def main():
    LoggerConfig.configure_log_file('example_log')
    logging.info('Log configuration successful.')

if __name__ == "__main__":
    main()
=====./core/logging/model_manager.py=====
import joblib
from core.logging.file_utils import FileUtils

class ModelManager:
    @staticmethod
    def save_model(model, filename, directory=None):
        file_path = FileUtils.save_file_with_timestamp(model, filename, directory)
        joblib.dump(model, file_path)
        return file_path

    @staticmethod
    def load_model(filename, directory=None):
        file_path = os.path.join(directory, filename) if directory else filename
        return joblib.load(file_path)

    @classmethod
    def save_all_models(cls, trained_models, directory, prefix='model'):
        saved_models = []
        for model_name, model_info in trained_models.items():
            filename = f"{prefix}_{model_name}.pkl"
            file_path = cls.save_model(model_info['model'], filename, directory)
            saved_models.append(file_path)
            print(f"Model '{model_name}' saved at: {file_path}")
        return saved_models=====./core/logging/file_utils.py=====
import os
from datetime import datetime
import pandas as pd

class FileUtils:
    @staticmethod
    def save_file(content, filename, directory=None, is_csv=False):
        directory = FileUtils._create_directory_if_not_exists(directory)
        file_path = os.path.join(directory, filename)
        
        if is_csv:
            content.to_csv(file_path, index=False)
        else:
            with open(file_path, 'w') as file:
                file.write(content)
        
        return file_path

    @staticmethod
    def save_file_with_timestamp(content, filename, directory=None, is_csv=False):
        filename_with_timestamp = FileUtils._generate_filename_with_timestamp(filename)
        return FileUtils.save_file(content, filename_with_timestamp, directory, is_csv)

    @staticmethod
    def _create_directory_if_not_exists(directory):
        if directory:
            os.makedirs(directory, exist_ok=True)
        return directory or ""

    @staticmethod
    def _generate_filename_with_timestamp(filename):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        name, ext = os.path.splitext(filename)
        return f"{name}_{timestamp}{ext}"=====./notebooks/notebook_script.py=====
# %%
import os
path = "/Users/patricia/Documents/code/python-code/behavior-detection/src"
os.chdir(path)  # Muda o diretório para o nível anterior (a raiz do projeto)
print(os.getcwd())  # Verifique se agora está na raiz

# %% [markdown]
# # Load data

# %%
from behavior.behavior_data_loader import BehaviorDataLoader

data_path = '../data/new_logs_labels.csv'

data = BehaviorDataLoader.load_data(data_path, delimiter=';')
print(data.shape)
data.head(5)

# %%
from core.preprocessors.data_cleaner import DataCleaner

print("Valores da coluna 'comportamento' antes da remoção:", data['comportamento'].value_counts())

# Remove instances where 'comportamento' is '?'
data = DataCleaner.remove_instances_with_value(data, 'comportamento', '?')

print("\nValores da coluna 'comportamento' depois da remoção:", data['comportamento'].value_counts())

# %%
data.head(5)

# %%
## Select a subset of the data only for testing purposes

# Selecionar um subconjunto dos dados
# print("Tamanho do dataframe antes:", data.shape)
data = data.sample(n=500, random_state=42)
data.reset_index(drop=True, inplace=True)
# print("Tamanho do dataframe após:", data.shape)

# %% [markdown]
# # Pre-processing
# 
# ## Remove unnecessary columns

# %%
# Removing columns related to IDs, emotions, personality and behaviors, because 
# we want to classify behaviors only by the students' interactions with the system
columns_to_remove_ids = ['id_log', 'grupo', 'num_dia', 'num_log']
columns_to_remove_emotions = [
    'estado_afetivo', 'estado_engajamento_concentrado', 
    'estado_confusao', 'estado_frustracao', 'estado_tedio', 'estado_indefinido', 
    'ultimo_estado_afetivo', 'ultimo_engajamento_concentrado', 'ultimo_confusao', 
    'ultimo_frustracao', 'ultimo_tedio', 'ultimo_estado_indefinido'
]
columns_to_remove_personality = [
    'traco_amabilidade_fator', 'traco_extrovercao_fator', 'traco_conscienciosidade_fator', 
    'traco_abertura_fator', 'traco_neuroticismo_fator', 'traco_amabilidade_cat', 
    'traco_extrovercao_cat', 'traco_conscienciosidade_cat', 'traco_abertura_cat', 
    'traco_neuroticismo_cat']

columns_to_remove_behaviors = [
    'comportamento_on_task', 'comportamento_on_task_conversation', 'comportamento_on_task_out',
    'comportamento_off_task', 'comportamento_on_system', 'comportamento_indefinido',
    'ultimo_comportamento', 'ultimo_comportamento_on_task', 'ultimo_comportamento_on_task_conversation',
    'ultimo_comportamento_on_task_out', 'ultimo_comportamento_off_task', 'ultimo_comportamento_on_system',
    'ultimo_comportamento_indefinido'
]

columns_to_remove = columns_to_remove_ids + \
        columns_to_remove_emotions + \
        columns_to_remove_personality + \
        columns_to_remove_behaviors

cleaned_data = DataCleaner.remove_columns(data, columns_to_remove)


# %%
cleaned_data.head(5)

# %%
# Preenche valores ausentes no DataFrame X com a string 'missing'.

cleaned_data = cleaned_data.fillna('missing')

# %% [markdown]
# ## Split data by student level into training and test datasets

# %%
from core.preprocessors.data_splitter import DataSplitter

train_data, test_data = DataSplitter.split_by_student_level(cleaned_data, test_size=0.2, column_name='aluno')

# %%
# removing the 'aluno' column from the data after splitting into train and test sets

# Remover 'aluno' do conjunto de treinamento
cleaned_data = DataCleaner.remove_columns(train_data, ['aluno'])

# Remover 'aluno' do conjunto de teste
cleaned_data = DataCleaner.remove_columns(test_data, ['aluno'])

# %% [markdown]
# ## Split data into Features (X) and Target (y)

# %%
from core.preprocessors.data_splitter import DataSplitter

# Conjunto de treinamento
X_train, y_train = DataSplitter.split_into_x_y(train_data, 'comportamento')

# Conjunto de teste
X_test, y_test = DataSplitter.split_into_x_y(test_data, 'comportamento')

# %%
print("Primeiras 5 instâncias de y_train:")
print(y_train[:5])

print("\nPrimeiras 5 instâncias de y_test:")
print(y_test[:5])

# %% [markdown]
# ## Encoding variables

# %% [markdown]
# ### Encoding true labels (y)

# %%
import importlib
from core.preprocessors import column_selector, data_encoder
from behavior import behavior_data_encoder

# Recarregar o módulo para garantir que as alterações sejam aplicadas
importlib.reload(column_selector)
importlib.reload(data_encoder)
importlib.reload(behavior_data_encoder)

# %%
# Encoding y_train and y_test
from behavior.behavior_data_encoder import BehaviorDataEncoder

# Codificar y_train
y_train = BehaviorDataEncoder.encode_y(y_train)

# Codificar y_test
y_test = BehaviorDataEncoder.encode_y(y_test)

# %% [markdown]
# ### Encoding features (X)

# %%
# Pré-processar X_train
X_encoder = BehaviorDataEncoder(num_classes=5)
X_encoder.fit(X_train)

X_train = X_encoder.transform(X_train)

# Pré-processar X_test usando o mesmo preprocessor
X_test = X_encoder.transform(X_test)

# %% [markdown]
# # Balanceamento dos dados

# %%
from core.preprocessors.data_balancer import DataBalancer

data_balancer = DataBalancer()
X_train, y_train = data_balancer.apply_smote(X_train, y_train)

# %%
from collections import Counter

print(f"Resampled dataset shape: {Counter(y_train)}")

# %% [markdown]
# # Treinamento dos Modelos

# %% [markdown]
# ## Definindo parametros

# %%
# Definir quais modelos e seletores utilizar
selected_models = None # None to use all models
selected_selectors = ['pca', 'rf']

cv = 5  # Number of folds in the cross-validation
n_iter = 100
n_jobs = 4  # Number of processors to be used in the execution: -1 to use all processors

# Choose a scoring metric
scoring_metric = 'roc_auc_ovr'  # Possible values: 'f1_macro', 'balanced_accuracy', 'roc_auc_ovr', etc.

# %% [markdown]
# ## Usando Otimização Bayesiana (BayesSearchCV)

# %%
# from core.training.skopt_bayesian_optimization_training import SkoptBayesianOptimizationTraining

# training = SkoptBayesianOptimizationTraining()

# #### Executar o treinamento
# trained_models = training.train_model(
#     X_train=X_train,
#     y_train=y_train,
#     selected_models=selected_models,
#     selected_selectors=selected_selectors,
#     n_iter=n_iter,
#     cv=cv,
#     scoring=scoring_metric,
#     n_jobs=n_jobs
# )

# #### Exemplo de acesso aos modelos treinados
# for model_key, model_info in trained_models.items():
#     print(f"Modelo: {model_key}")
#     print(f"Melhores Hiperparâmetros: {model_info['hyperparameters']}")
#     print(f"Resultado CV: {model_info['cv_result']}\n") 

# %% [markdown]
# ## Usando Otimização Bayesiana (Optuna)

# %%
# Importação da nova classe OptunaBayesianOptimizationTraining
from core.training.optuna_bayesian_optimization_training import OptunaBayesianOptimizationTraining

# Instanciação da classe de treinamento com Otimização Bayesiana via Optuna
training = OptunaBayesianOptimizationTraining()

# Executar o treinamento
trained_models = training.train_model(
    X_train=X_train,
    y_train=y_train,
    selected_models=selected_models,
    selected_selectors=selected_selectors,
    n_iter=n_iter,  # Será mapeado para n_trials na classe OptunaBayesianOptimizationTraining
    cv=cv,
    scoring=scoring_metric,
    n_jobs=n_jobs
)

# Exemplo de acesso aos modelos treinados
for model_key, model_info in trained_models.items():
    print(f"Modelo: {model_key}")
    print(f"Melhores Hiperparâmetros: {model_info['hyperparameters']}")
    print(f"Resultado CV: {model_info['cv_result']}\n")


# %% [markdown]
# # Avaliação dos Modelos

# %%
from core.evaluation.evaluation import Evaluation  

feature_names = X_train.columns  # Assumindo que os nomes das características são as colunas
class_metrics_results, avg_metrics_results = Evaluation.evaluate_all_models(trained_models, X_train, y_train, X_test, y_test, feature_names)

# %% [markdown]
# # Geração dos Relatórios

# %%
from core.logging.report_formatter import ReportFormatter
from core.logging.file_utils import FileUtils

directory = "../output/"

# Gerar relatório textual a partir dos resultados de avaliação
text_report = ReportFormatter.generate_text_report(class_metrics_results, avg_metrics_results)

# Imprimir ou salvar o relatório
FileUtils.save_file_with_timestamp(text_report, "bayesian_optimization_report.txt", directory)

# Gerar DataFrame detalhado dos relatórios por classe
class_report_df = ReportFormatter.generate_class_report_dataframe(class_metrics_results)

# Gerar DataFrame resumido dos relatórios de métricas médias
avg_metrics_report_df = ReportFormatter.generate_avg_metrics_report_dataframe(avg_metrics_results)

# Salvar os DataFrames como arquivos CSV, se necessário
FileUtils.save_csv_file_with_timestamp(class_report_df, "class_report.csv", directory)
FileUtils.save_csv_file_with_timestamp(avg_metrics_report_df, "avg_metrics_report.csv", directory)


# %% [markdown]
# 

# %% [markdown]
# # Salvando os modelos em arquivos para recuperação

# %%
from core.logging.model_manager import ModelManager

# Caminhos
model_dir = "../models/"

# Salvar todos os modelos
saved_models = ModelManager.save_all_models(trained_models, model_dir)
print("Modelos salvos:", saved_models)


