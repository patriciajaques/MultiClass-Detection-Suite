{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training\n",
    "import preprocessing as pre\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ON TASK\n",
       "1    ON TASK\n",
       "2    ON TASK\n",
       "3    ON TASK\n",
       "4    ON TASK\n",
       "Name: comportamento, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No notebook\n",
    "data_path = '../data/new_logs_labels.csv'\n",
    "X, y = pre.load_data(data_path)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna('missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 4391\n",
      "Tamanho do conjunto de teste: 1098\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2  # 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = pre.split_train_test_data(X, y, test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "ON TASK                 2553\n",
      "ON SYSTEM                721\n",
      "OFF TASK                 495\n",
      "ON TASK CONVERSATION     321\n",
      "ON TASK OUT              301\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Nro de instancias de cada classe em y_test:\n",
      "\n",
      "ON TASK                 606\n",
      "ON SYSTEM               186\n",
      "OFF TASK                134\n",
      "ON TASK CONVERSATION     93\n",
      "ON TASK OUT              79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns in X_train:\n",
      "Index(['log_type'], dtype='object')\n",
      "\n",
      "Non-numeric columns in X_test:\n",
      "Index(['log_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols_train = X_train.select_dtypes(exclude=['float', 'int']).columns\n",
    "non_numeric_cols_test = X_test.select_dtypes(exclude=['float', 'int']).columns\n",
    "\n",
    "print(\"Non-numeric columns in X_train:\")\n",
    "print(non_numeric_cols_train)\n",
    "\n",
    "print(\"\\nNon-numeric columns in X_test:\")\n",
    "print(non_numeric_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, label_encoders = pre.encode_categorical_columns(X_train)\n",
    "X_test = pre.apply_encoders_to_test_data(X_test, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "ON TASK                 2553\n",
      "ON SYSTEM                721\n",
      "OFF TASK                 495\n",
      "ON TASK CONVERSATION     321\n",
      "ON TASK OUT              301\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Nro de instancias de cada classe em y_test:\n",
      "\n",
      "ON TASK                 606\n",
      "ON SYSTEM               186\n",
      "OFF TASK                134\n",
      "ON TASK CONVERSATION     93\n",
      "ON TASK OUT              79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, label_encoder = pre.encode_single_column(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = pre.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "1    2553\n",
      "2    2553\n",
      "0    2553\n",
      "3    2553\n",
      "4    2553\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train_over).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos das colunas de X_train_over:\n",
      "\n",
      "Tipos das colunas de X_test:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Visualizar os tipos das colunas de X_train_over\n",
    "print(\"Tipos das colunas de X_train_over:\")\n",
    "x_train_types = X_train_over.dtypes\n",
    "\n",
    "# Visualizar os tipos das colunas de X_test\n",
    "print(\"\\nTipos das colunas de X_test:\")\n",
    "X_test_types = X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-processar os dados uma vez\n",
    "preprocessor = pre.create_preprocessor(X_train_over)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train_over)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65819387 0.75862069 0.77777778 ... 0.         0.         0.        ]\n",
      " [0.99729108 0.68965517 0.55555556 ... 0.         0.         0.        ]\n",
      " [0.99854326 0.89655172 0.         ... 0.         0.         0.        ]\n",
      " [0.99462421 0.20689655 0.88888889 ... 0.         0.         0.        ]\n",
      " [0.99504288 0.27586207 1.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_preprocessed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12765, 336)\n",
      "                0             1             2             3             4    \\\n",
      "count  12765.000000  12765.000000  12765.000000  12765.000000  12765.000000   \n",
      "mean       0.824813      0.541910      0.520999      0.546390      0.339597   \n",
      "std        0.282219      0.291098      0.311387      0.310065      0.196976   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.660264      0.310345      0.222222      0.333333      0.174377   \n",
      "50%        0.995366      0.551724      0.555556      0.555556      0.341637   \n",
      "75%        0.997872      0.793103      0.777778      0.777778      0.487544   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                5             6             7             8             9    \\\n",
      "count  12765.000000  12765.000000  12765.000000  12765.000000  12765.000000   \n",
      "mean       0.653858      0.022170      0.001488      0.023188      0.069719   \n",
      "std        0.254601      0.147242      0.038553      0.150507      0.129823   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.500000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.800000      0.000000      0.000000      0.000000      0.022727   \n",
      "75%        0.800000      0.000000      0.000000      0.000000      0.072727   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       ...           326           327           328      329      330  \\\n",
      "count  ...  12765.000000  12765.000000  12765.000000  12765.0  12765.0   \n",
      "mean   ...      0.083588      0.069142      0.077512      0.0      0.0   \n",
      "std    ...      0.218846      0.231026      0.225628      0.0      0.0   \n",
      "min    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "75%    ...      0.000000      0.000000      0.111111      0.0      0.0   \n",
      "max    ...      1.000000      1.000000      1.000000      0.0      0.0   \n",
      "\n",
      "                331           332           333      334           335  \n",
      "count  12765.000000  12765.000000  12765.000000  12765.0  12765.000000  \n",
      "mean       0.070897      0.053114      0.106933      0.0      0.034140  \n",
      "std        0.255439      0.224270      0.255393      0.0      0.180679  \n",
      "min        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "25%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "50%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "75%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "max        1.000000      1.000000      1.000000      0.0      1.000000  \n",
      "\n",
      "[8 rows x 336 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_preprocessed.shape)\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que 'X_train_preprocessed' seja seu numpy.ndarray\n",
    "df = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Agora voc√™ pode chamar .describe() no DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names:  Index(['id_log', 'aluno', 'grupo', 'num_dia', 'num_log', 'log_type',\n",
      "       'ultimo_passo_correto', 'verificado_com_mouse',\n",
      "       'verificado_com_teclado', 'idle_time_acumulado',\n",
      "       ...\n",
      "       'misc_OI_Mt_Plus_Sb_total', 'misc_OI_Dv_Plus_Sb_total',\n",
      "       'misc_EqSec_Distrib_MtTerm_total', 'misc_OI_Mt_Minus_Mt_Plus_total',\n",
      "       'misc_OI_Mt_Minus_Mt_Minus_total', 'misc_OI_Dv_Plus_Ad_total',\n",
      "       'misc_EqPrim_Mt_Inc_total', 'misc_EqPrim_Dv_Inc_total',\n",
      "       'misc_OI_Dv_Minus_Dv_Minus_total',\n",
      "       'misc_EqSec_OpFrac_MMC_MtNumerador_total'],\n",
      "      dtype='object', length=336)\n"
     ]
    }
   ],
   "source": [
    "# Gera√ß√£o dos relat√≥rios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das caracter√≠sticas s√£o as colunas\n",
    "print(\"feature_names: \", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_preprocessed shape: (12765, 336)\n",
      "y_train shape: (12765,)\n"
     ]
    }
   ],
   "source": [
    "# Verifica√ß√£o antes de chamar a fun√ß√£o de treinamento\n",
    "print(f\"X_train_preprocessed shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"y_train shape: {y_train_over.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Decision Tree with Bayesian Optimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_features_to_select=10;, score=0.848 total time= 6.3min\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_features_to_select=10;, score=0.847 total time= 6.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_features_to_select=50;, score=0.950 total time= 5.7min\n",
      "[CV 1/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_features_to_select=50;, score=0.947 total time= 6.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_features_to_select=20;, score=0.859 total time= 6.2min\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_features_to_select=20;, score=0.857 total time= 6.6min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=20, classifier__min_samples_leaf=3, classifier__min_samples_split=13, feature_selection__n_features_to_select=40;, score=0.952 total time= 5.8min\n",
      "[CV 1/2] END classifier__max_depth=20, classifier__min_samples_leaf=3, classifier__min_samples_split=13, feature_selection__n_features_to_select=40;, score=0.942 total time= 6.2min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=20, classifier__min_samples_leaf=5, classifier__min_samples_split=11, feature_selection__n_features_to_select=40;, score=0.953 total time= 5.8min\n",
      "[CV 1/2] END classifier__max_depth=20, classifier__min_samples_leaf=5, classifier__min_samples_split=11, feature_selection__n_features_to_select=40;, score=0.941 total time= 6.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=20, classifier__min_samples_leaf=9, classifier__min_samples_split=5, feature_selection__n_features_to_select=5;, score=0.949 total time= 6.2min\n",
      "[CV 1/2] END classifier__max_depth=20, classifier__min_samples_leaf=9, classifier__min_samples_split=5, feature_selection__n_features_to_select=5;, score=0.945 total time= 6.6min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=10, classifier__min_samples_leaf=8, classifier__min_samples_split=8, feature_selection__n_features_to_select=50;, score=0.945 total time= 5.6min\n",
      "[CV 1/2] END classifier__max_depth=10, classifier__min_samples_leaf=8, classifier__min_samples_split=8, feature_selection__n_features_to_select=50;, score=0.940 total time= 6.0min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=10, classifier__min_samples_leaf=9, classifier__min_samples_split=11, feature_selection__n_features_to_select=40;, score=0.944 total time= 5.8min\n",
      "[CV 1/2] END classifier__max_depth=10, classifier__min_samples_leaf=9, classifier__min_samples_split=11, feature_selection__n_features_to_select=40;, score=0.935 total time= 6.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=30, classifier__min_samples_leaf=7, classifier__min_samples_split=18, feature_selection__n_features_to_select=10;, score=0.945 total time= 6.2min\n",
      "[CV 1/2] END classifier__max_depth=30, classifier__min_samples_leaf=7, classifier__min_samples_split=18, feature_selection__n_features_to_select=10;, score=0.944 total time= 6.6min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=None, classifier__min_samples_leaf=8, classifier__min_samples_split=15, feature_selection__n_features_to_select=5;, score=0.951 total time= 6.2min\n",
      "[CV 1/2] END classifier__max_depth=None, classifier__min_samples_leaf=8, classifier__min_samples_split=15, feature_selection__n_features_to_select=5;, score=0.947 total time= 6.6min\n",
      "Bayesian Optimization Best Result for Decision Tree with rfe: 0.9488415725672283\n",
      "Training and evaluating Decision Tree with Bayesian Optimization and pca:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_components=10;, score=0.808 total time=   0.1s\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_components=10;, score=0.827 total time=   0.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_components=50;, score=0.936 total time=   0.4s\n",
      "[CV 1/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_components=50;, score=0.916 total time=   0.4s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_components=20;, score=0.838 total time=   0.2s\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_components=20;, score=0.823 total time=   0.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=20, classifier__min_samples_leaf=3, classifier__min_samples_split=13, feature_selection__n_components=40;, score=0.924 total time=   0.4s\n",
      "[CV 1/2] END classifier__max_depth=20, classifier__min_samples_leaf=3, classifier__min_samples_split=13, feature_selection__n_components=40;, score=0.912 total time=   0.4s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__max_depth=20, classifier__min_samples_leaf=5, classifier__min_samples_split=11, feature_selection__n_components=40;, score=0.919 total time=   0.3s\n",
      "[CV 2/2] END classifier__max_depth=20, classifier__min_samples_leaf=5, classifier__min_samples_split=11, feature_selection__n_components=40;, score=0.926 total time=   0.4s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=20, classifier__min_samples_leaf=9, classifier__min_samples_split=5, feature_selection__n_components=5;, score=0.933 total time=   0.1s\n",
      "[CV 1/2] END classifier__max_depth=20, classifier__min_samples_leaf=9, classifier__min_samples_split=5, feature_selection__n_components=5;, score=0.922 total time=   0.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=10, classifier__min_samples_leaf=8, classifier__min_samples_split=8, feature_selection__n_components=50;, score=0.925 total time=   0.5s\n",
      "[CV 1/2] END classifier__max_depth=10, classifier__min_samples_leaf=8, classifier__min_samples_split=8, feature_selection__n_components=50;, score=0.914 total time=   0.5s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__max_depth=10, classifier__min_samples_leaf=9, classifier__min_samples_split=11, feature_selection__n_components=40;, score=0.914 total time=   0.4s\n",
      "[CV 2/2] END classifier__max_depth=10, classifier__min_samples_leaf=9, classifier__min_samples_split=11, feature_selection__n_components=40;, score=0.922 total time=   0.4s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=30, classifier__min_samples_leaf=7, classifier__min_samples_split=18, feature_selection__n_components=10;, score=0.933 total time=   0.2s\n",
      "[CV 1/2] END classifier__max_depth=30, classifier__min_samples_leaf=7, classifier__min_samples_split=18, feature_selection__n_components=10;, score=0.921 total time=   0.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=None, classifier__min_samples_leaf=8, classifier__min_samples_split=15, feature_selection__n_components=5;, score=0.933 total time=   0.3s\n",
      "[CV 1/2] END classifier__max_depth=None, classifier__min_samples_leaf=8, classifier__min_samples_split=15, feature_selection__n_components=5;, score=0.922 total time=   0.3s\n",
      "Bayesian Optimization Best Result for Decision Tree with pca: 0.9279046205181471\n"
     ]
    }
   ],
   "source": [
    "cv = 2\n",
    "n_iter = 10\n",
    "\n",
    "# Escolher a m√©trica de avalia√ß√£o\n",
    "scoring_metric = 'roc_auc_ovr'  # Pode ser 'f1_macro', 'balanced_accuracy', 'roc_auc_ovr', etc.\n",
    "\n",
    "# Chamar o treinamento com otimiza√ß√£o bayesiana\n",
    "trained_models = training.train_model(\n",
    "    X_train_preprocessed, y_train_over, training.BAYESIAN_OPTIMIZATION, n_iter=n_iter, cv=cv, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/Users/patricia/Documents/code/python-code/behavior-detection/src/evaluation.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cv_conf_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m reports \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mgenerate_reports(trained_models, X_train_preprocessed, y_train_over, X_test_preprocessed, y_test, feature_names)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Impress√£o dos relat√≥rios\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluation\u001b[38;5;241m.\u001b[39mprint_reports(reports, dirpath))\n\u001b[1;32m     12\u001b[0m evaluation\u001b[38;5;241m.\u001b[39msave_reports_to_csv(reports, dirpath)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Salvar todos os modelos\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/python-code/behavior-detection/src/evaluation.py:162\u001b[0m, in \u001b[0;36mprint_reports\u001b[0;34m(reports, directory, filename)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     report_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSelected Features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(selected_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eval_type, set_name, report, conf_matrix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    159\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCross-Validation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    160\u001b[0m         [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcross-validation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    161\u001b[0m         [model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_report\u001b[39m\u001b[38;5;124m'\u001b[39m], model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_report\u001b[39m\u001b[38;5;124m'\u001b[39m], model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_report\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m--> 162\u001b[0m         [model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_conf_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m], model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_conf_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m], model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_conf_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m     report_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00meval_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m set report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m     report_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m format_report(report)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cv_conf_matrix'"
     ]
    }
   ],
   "source": [
    "# Caminhos\n",
    "dirpath = \"../output/\"\n",
    "model_dir = \"../models/\"\n",
    "\n",
    "# Gera√ß√£o dos relat√≥rios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das caracter√≠sticas s√£o as colunas\n",
    "reports = evaluation.generate_reports(trained_models, X_train_preprocessed, y_train_over, X_test_preprocessed, y_test, feature_names)\n",
    "\n",
    "# Impress√£o dos relat√≥rios\n",
    "print(evaluation.print_reports(reports, dirpath))\n",
    "\n",
    "evaluation.save_reports_to_csv(reports, dirpath)\n",
    "\n",
    "# Salvar todos os modelos\n",
    "saved_models = evaluation.dump_all_models(trained_models, model_dir)\n",
    "print(\"Modelos salvos:\", saved_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetos_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
