{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ON TASK\n",
       "1    ON TASK\n",
       "2    ON TASK\n",
       "3    ON TASK\n",
       "4    ON TASK\n",
       "Name: comportamento, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No notebook\n",
    "data_path = '../data/new_logs_labels.csv'\n",
    "X, y = pre.load_data(data_path)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna('missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 4391\n",
      "Tamanho do conjunto de teste: 1098\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2  # 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = pre.split_train_test_data(X, y, test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "ON TASK                 2553\n",
      "ON SYSTEM                721\n",
      "OFF TASK                 495\n",
      "ON TASK CONVERSATION     321\n",
      "ON TASK OUT              301\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Nro de instancias de cada classe em y_test:\n",
      "\n",
      "ON TASK                 606\n",
      "ON SYSTEM               186\n",
      "OFF TASK                134\n",
      "ON TASK CONVERSATION     93\n",
      "ON TASK OUT              79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns in X_train:\n",
      "Index(['log_type'], dtype='object')\n",
      "\n",
      "Non-numeric columns in X_test:\n",
      "Index(['log_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols_train = X_train.select_dtypes(exclude=['float', 'int']).columns\n",
    "non_numeric_cols_test = X_test.select_dtypes(exclude=['float', 'int']).columns\n",
    "\n",
    "print(\"Non-numeric columns in X_train:\")\n",
    "print(non_numeric_cols_train)\n",
    "\n",
    "print(\"\\nNon-numeric columns in X_test:\")\n",
    "print(non_numeric_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, label_encoders = pre.encode_categorical_columns(X_train)\n",
    "X_test = pre.apply_encoders_to_test_data(X_test, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "ON TASK                 2553\n",
      "ON SYSTEM                721\n",
      "OFF TASK                 495\n",
      "ON TASK CONVERSATION     321\n",
      "ON TASK OUT              301\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Nro de instancias de cada classe em y_test:\n",
      "\n",
      "ON TASK                 606\n",
      "ON SYSTEM               186\n",
      "OFF TASK                134\n",
      "ON TASK CONVERSATION     93\n",
      "ON TASK OUT              79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, label_encoder = pre.encode_single_column(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = pre.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "1    2553\n",
      "2    2553\n",
      "0    2553\n",
      "3    2553\n",
      "4    2553\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train_over).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos das colunas de X_train_over:\n",
      "\n",
      "Tipos das colunas de X_test:\n"
     ]
    }
   ],
   "source": [
    "# Visualizar os tipos das colunas de X_train_over\n",
    "print(\"Tipos das colunas de X_train_over:\")\n",
    "x_train_types = X_train_over.dtypes\n",
    "\n",
    "# Visualizar os tipos das colunas de X_test\n",
    "print(\"\\nTipos das colunas de X_test:\")\n",
    "X_test_types = X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processar os dados uma vez\n",
    "preprocessor = pre.create_preprocessor(X_train_over)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train_over)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65819387 0.75862069 0.77777778 ... 0.         0.         0.        ]\n",
      " [0.99729108 0.68965517 0.55555556 ... 0.         0.         0.        ]\n",
      " [0.99854326 0.89655172 0.         ... 0.         0.         0.        ]\n",
      " [0.99462421 0.20689655 0.88888889 ... 0.         0.         0.        ]\n",
      " [0.99504288 0.27586207 1.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_preprocessed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12765, 336)\n",
      "                0             1             2             3             4    \\\n",
      "count  12765.000000  12765.000000  12765.000000  12765.000000  12765.000000   \n",
      "mean       0.824813      0.541910      0.520999      0.546390      0.339597   \n",
      "std        0.282219      0.291098      0.311387      0.310065      0.196976   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.660264      0.310345      0.222222      0.333333      0.174377   \n",
      "50%        0.995366      0.551724      0.555556      0.555556      0.341637   \n",
      "75%        0.997872      0.793103      0.777778      0.777778      0.487544   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                5             6             7             8             9    \\\n",
      "count  12765.000000  12765.000000  12765.000000  12765.000000  12765.000000   \n",
      "mean       0.653858      0.022170      0.001488      0.023188      0.069719   \n",
      "std        0.254601      0.147242      0.038553      0.150507      0.129823   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.500000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.800000      0.000000      0.000000      0.000000      0.022727   \n",
      "75%        0.800000      0.000000      0.000000      0.000000      0.072727   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       ...           326           327           328      329      330  \\\n",
      "count  ...  12765.000000  12765.000000  12765.000000  12765.0  12765.0   \n",
      "mean   ...      0.083588      0.069142      0.077512      0.0      0.0   \n",
      "std    ...      0.218846      0.231026      0.225628      0.0      0.0   \n",
      "min    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "75%    ...      0.000000      0.000000      0.111111      0.0      0.0   \n",
      "max    ...      1.000000      1.000000      1.000000      0.0      0.0   \n",
      "\n",
      "                331           332           333      334           335  \n",
      "count  12765.000000  12765.000000  12765.000000  12765.0  12765.000000  \n",
      "mean       0.070897      0.053114      0.106933      0.0      0.034140  \n",
      "std        0.255439      0.224270      0.255393      0.0      0.180679  \n",
      "min        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "25%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "50%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "75%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "max        1.000000      1.000000      1.000000      0.0      1.000000  \n",
      "\n",
      "[8 rows x 336 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_preprocessed.shape)\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que 'X_train_preprocessed' seja seu numpy.ndarray\n",
    "df = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Agora você pode chamar .describe() no DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names:  Index(['id_log', 'aluno', 'grupo', 'num_dia', 'num_log', 'log_type',\n",
      "       'ultimo_passo_correto', 'verificado_com_mouse',\n",
      "       'verificado_com_teclado', 'idle_time_acumulado',\n",
      "       ...\n",
      "       'misc_OI_Mt_Plus_Sb_total', 'misc_OI_Dv_Plus_Sb_total',\n",
      "       'misc_EqSec_Distrib_MtTerm_total', 'misc_OI_Mt_Minus_Mt_Plus_total',\n",
      "       'misc_OI_Mt_Minus_Mt_Minus_total', 'misc_OI_Dv_Plus_Ad_total',\n",
      "       'misc_EqPrim_Mt_Inc_total', 'misc_EqPrim_Dv_Inc_total',\n",
      "       'misc_OI_Dv_Minus_Dv_Minus_total',\n",
      "       'misc_EqSec_OpFrac_MMC_MtNumerador_total'],\n",
      "      dtype='object', length=336)\n"
     ]
    }
   ],
   "source": [
    "# Geração dos relatórios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das características são as colunas\n",
    "print(\"feature_names: \", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_preprocessed shape: (12765, 336)\n",
      "y_train shape: (12765,)\n"
     ]
    }
   ],
   "source": [
    "# Verificação antes de chamar a função de treinamento\n",
    "print(f\"X_train_preprocessed shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"y_train shape: {y_train_over.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento dos Modelos usando Otimização Bayesiana (BayesSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Logistic Regression with BayesianOptimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    }
   ],
   "source": [
    "from bayesian_optimization_training import BayesianOptimizationTraining\n",
    "cv = 2\n",
    "n_iter = 3\n",
    "\n",
    "# Escolher a métrica de avaliação\n",
    "scoring_metric = 'roc_auc_ovr'  # Pode ser 'f1_macro', 'balanced_accuracy', 'roc_auc_ovr', etc.\n",
    "\n",
    "# Instanciar a classe BayesianOptimizationTraining\n",
    "training = BayesianOptimizationTraining()\n",
    "\n",
    "\n",
    "# Chamar o treinamento com otimização bayesiana\n",
    "trained_models = training.train_model(\n",
    "    X_train_preprocessed, y_train_over, n_iter=n_iter, cv=cv, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import evaluation  # Importa o módulo evaluation\n",
    "importlib.reload(evaluation)  # Recarrega o módulo evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import Evaluation \n",
    "\n",
    "# Geração dos relatórios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das características são as colunas\n",
    "evaluation_results = Evaluation.evaluate_all_models(trained_models, X_train_preprocessed, y_train_over, X_test_preprocessed, y_test, feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração dos Relatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import report_formatter  # Importa o módulo evaluation\n",
    "importlib.reload(report_formatter)  # Recarrega o módulo evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from report_formatter import ReportFormatter\n",
    "from file_manager import FileManager\n",
    "\n",
    "directory = \"../output/\"\n",
    "\n",
    "# Impressão dos relatórios\n",
    "\n",
    "# Gerar relatório textual a partir dos resultados de avaliação\n",
    "text_report = ReportFormatter.generate_text_report_from_dict(evaluation_results)\n",
    "\n",
    "# Imprimir ou salvar o relatório\n",
    "FileManager.save_text_file_with_timestamp(text_report, \"bayesian_optimization_report.txt\", directory)\n",
    "\n",
    "# Opcional: Gerar DataFrame detalhado e resumido dos relatórios\n",
    "detailed_df = ReportFormatter.generate_detailed_report_dataframe(evaluation_results)\n",
    "summary_df = ReportFormatter.generate_summary_report_dataframe(evaluation_results)\n",
    "\n",
    "# Salvar os DataFrames como arquivos CSV, se necessário\n",
    "FileManager.save_csv_file_with_timestamp(detailed_df, \"detailed_report.csv\", directory)\n",
    "FileManager.save_csv_file_with_timestamp(summary_df, \"summary_report.csv\", directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando os modelos em arquivos para recuperação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_manager import ModelManager\n",
    "\n",
    "# Caminhos\n",
    "model_dir = \"../models/\"\n",
    "\n",
    "# Salvar todos os modelos\n",
    "saved_models = ModelManager.dump_all_models(trained_models, model_dir)\n",
    "print(\"Modelos salvos:\", saved_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetos_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
