{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (training.py, line 14)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/opt/anaconda3/envs/projetos_ML/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\n\u001b[0;31m    import training\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/code/python-code/behavior-detection/src/training.py:14\u001b[0;36m\u001b[0m\n\u001b[0;31m    def train_model (X_train., y_train, training_type, n_iter=50, cv=5, scoring='balanced_accuracy'):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import training\n",
    "import preprocessing as pre\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No notebook\n",
    "data_path = '../data/new_logs_labels.csv'\n",
    "X, y = pre.load_data(data_path)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna('missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2  # 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = pre.split_train_test_data(X, y, test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols_train = X_train.select_dtypes(exclude=['float', 'int']).columns\n",
    "non_numeric_cols_test = X_test.select_dtypes(exclude=['float', 'int']).columns\n",
    "\n",
    "print(\"Non-numeric columns in X_train:\")\n",
    "print(non_numeric_cols_train)\n",
    "\n",
    "print(\"\\nNon-numeric columns in X_test:\")\n",
    "print(non_numeric_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, label_encoders = pre.encode_categorical_columns(X_train)\n",
    "X_test = pre.apply_encoders_to_test_data(X_test, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, label_encoder = pre.encode_single_column(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = pre.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train_over).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Visualizar os tipos das colunas de X_train_over\n",
    "print(\"Tipos das colunas de X_train_over:\")\n",
    "x_train_types = X_train_over.dtypes\n",
    "\n",
    "# Visualizar os tipos das colunas de X_test\n",
    "print(\"\\nTipos das colunas de X_test:\")\n",
    "X_test_types = X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processar os dados uma vez\n",
    "preprocessor = pre.create_preprocessor(X_train_over)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train_over)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_preprocessed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_preprocessed.shape)\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que 'X_train_preprocessed' seja seu numpy.ndarray\n",
    "df = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Agora você pode chamar .describe() no DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração dos relatórios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das características são as colunas\n",
    "print(\"feature_names: \", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação antes de chamar a função de treinamento\n",
    "print(f\"X_train_preprocessed shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"y_train shape: {y_train_over.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 10\n",
    "n_iter = 100\n",
    "\n",
    "# Escolher a métrica de avaliação\n",
    "scoring_metric = 'roc_auc_ovr'  # Pode ser 'f1_macro', 'balanced_accuracy', 'roc_auc_ovr', etc.\n",
    "\n",
    "# Chamar o treinamento com otimização bayesiana\n",
    "trained_models = training.train_model(\n",
    "    X_train_preprocessed, y_train_over, training.BAYESIAN_OPTIMIZATION, n_iter=n_iter, cv=cv, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos\n",
    "dirpath = \"../output/\"\n",
    "model_dir = \"../models/\"\n",
    "\n",
    "# Geração dos relatórios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das características são as colunas\n",
    "reports = evaluation.generate_reports(trained_models, X_train_preprocessed, y_train_over, X_test_preprocessed, y_test, feature_names)\n",
    "\n",
    "# Impressão dos relatórios\n",
    "print(evaluation.print_reports(reports, dirpath))\n",
    "\n",
    "evaluation.save_reports_to_csv(reports, dirpath)\n",
    "\n",
    "# Salvar todos os modelos\n",
    "saved_models = evaluation.dump_all_models(trained_models, model_dir)\n",
    "print(\"Modelos salvos:\", saved_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetos_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
