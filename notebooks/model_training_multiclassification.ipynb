{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ON TASK\n",
       "1    ON TASK\n",
       "2    ON TASK\n",
       "3    ON TASK\n",
       "4    ON TASK\n",
       "Name: comportamento, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No notebook\n",
    "data_path = '../data/new_logs_labels.csv'\n",
    "X, y = pre.load_data(data_path)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna('missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 4391\n",
      "Tamanho do conjunto de teste: 1098\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2  # 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = pre.split_train_test_data(X, y, test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "ON TASK                 2553\n",
      "ON SYSTEM                721\n",
      "OFF TASK                 495\n",
      "ON TASK CONVERSATION     321\n",
      "ON TASK OUT              301\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Nro de instancias de cada classe em y_test:\n",
      "\n",
      "ON TASK                 606\n",
      "ON SYSTEM               186\n",
      "OFF TASK                134\n",
      "ON TASK CONVERSATION     93\n",
      "ON TASK OUT              79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns in X_train:\n",
      "Index(['log_type'], dtype='object')\n",
      "\n",
      "Non-numeric columns in X_test:\n",
      "Index(['log_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "non_numeric_cols_train = X_train.select_dtypes(exclude=['float', 'int']).columns\n",
    "non_numeric_cols_test = X_test.select_dtypes(exclude=['float', 'int']).columns\n",
    "\n",
    "print(\"Non-numeric columns in X_train:\")\n",
    "print(non_numeric_cols_train)\n",
    "\n",
    "print(\"\\nNon-numeric columns in X_test:\")\n",
    "print(non_numeric_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, label_encoders = pre.encode_categorical_columns(X_train)\n",
    "X_test = pre.apply_encoders_to_test_data(X_test, label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "ON TASK                 2553\n",
      "ON SYSTEM                721\n",
      "OFF TASK                 495\n",
      "ON TASK CONVERSATION     321\n",
      "ON TASK OUT              301\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Nro de instancias de cada classe em y_test:\n",
      "\n",
      "ON TASK                 606\n",
      "ON SYSTEM               186\n",
      "OFF TASK                134\n",
      "ON TASK CONVERSATION     93\n",
      "ON TASK OUT              79\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\n\\nNro de instancias de cada classe em y_test:\\n\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, label_encoder = pre.encode_single_column(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, y_train_over = pre.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nro de instancias de cada classe em y_train:\n",
      "\n",
      "1    2553\n",
      "2    2553\n",
      "0    2553\n",
      "3    2553\n",
      "4    2553\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Nro de instancias de cada classe em y_train:\\n\")\n",
    "print(pd.Series(y_train_over).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos das colunas de X_train_over:\n",
      "\n",
      "Tipos das colunas de X_test:\n"
     ]
    }
   ],
   "source": [
    "# Visualizar os tipos das colunas de X_train_over\n",
    "print(\"Tipos das colunas de X_train_over:\")\n",
    "x_train_types = X_train_over.dtypes\n",
    "\n",
    "# Visualizar os tipos das colunas de X_test\n",
    "print(\"\\nTipos das colunas de X_test:\")\n",
    "X_test_types = X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©-processar os dados uma vez\n",
    "preprocessor = pre.create_preprocessor(X_train_over)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train_over)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65819387 0.75862069 0.77777778 ... 0.         0.         0.        ]\n",
      " [0.99729108 0.68965517 0.55555556 ... 0.         0.         0.        ]\n",
      " [0.99854326 0.89655172 0.         ... 0.         0.         0.        ]\n",
      " [0.99462421 0.20689655 0.88888889 ... 0.         0.         0.        ]\n",
      " [0.99504288 0.27586207 1.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_preprocessed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12765, 336)\n",
      "                0             1             2             3             4    \\\n",
      "count  12765.000000  12765.000000  12765.000000  12765.000000  12765.000000   \n",
      "mean       0.824813      0.541910      0.520999      0.546390      0.339597   \n",
      "std        0.282219      0.291098      0.311387      0.310065      0.196976   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.660264      0.310345      0.222222      0.333333      0.174377   \n",
      "50%        0.995366      0.551724      0.555556      0.555556      0.341637   \n",
      "75%        0.997872      0.793103      0.777778      0.777778      0.487544   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                5             6             7             8             9    \\\n",
      "count  12765.000000  12765.000000  12765.000000  12765.000000  12765.000000   \n",
      "mean       0.653858      0.022170      0.001488      0.023188      0.069719   \n",
      "std        0.254601      0.147242      0.038553      0.150507      0.129823   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.500000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.800000      0.000000      0.000000      0.000000      0.022727   \n",
      "75%        0.800000      0.000000      0.000000      0.000000      0.072727   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       ...           326           327           328      329      330  \\\n",
      "count  ...  12765.000000  12765.000000  12765.000000  12765.0  12765.0   \n",
      "mean   ...      0.083588      0.069142      0.077512      0.0      0.0   \n",
      "std    ...      0.218846      0.231026      0.225628      0.0      0.0   \n",
      "min    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.0      0.0   \n",
      "75%    ...      0.000000      0.000000      0.111111      0.0      0.0   \n",
      "max    ...      1.000000      1.000000      1.000000      0.0      0.0   \n",
      "\n",
      "                331           332           333      334           335  \n",
      "count  12765.000000  12765.000000  12765.000000  12765.0  12765.000000  \n",
      "mean       0.070897      0.053114      0.106933      0.0      0.034140  \n",
      "std        0.255439      0.224270      0.255393      0.0      0.180679  \n",
      "min        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "25%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "50%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "75%        0.000000      0.000000      0.000000      0.0      0.000000  \n",
      "max        1.000000      1.000000      1.000000      0.0      1.000000  \n",
      "\n",
      "[8 rows x 336 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_preprocessed.shape)\n",
    "import pandas as pd\n",
    "\n",
    "# Supondo que 'X_train_preprocessed' seja seu numpy.ndarray\n",
    "df = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Agora voc√™ pode chamar .describe() no DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names:  Index(['id_log', 'aluno', 'grupo', 'num_dia', 'num_log', 'log_type',\n",
      "       'ultimo_passo_correto', 'verificado_com_mouse',\n",
      "       'verificado_com_teclado', 'idle_time_acumulado',\n",
      "       ...\n",
      "       'misc_OI_Mt_Plus_Sb_total', 'misc_OI_Dv_Plus_Sb_total',\n",
      "       'misc_EqSec_Distrib_MtTerm_total', 'misc_OI_Mt_Minus_Mt_Plus_total',\n",
      "       'misc_OI_Mt_Minus_Mt_Minus_total', 'misc_OI_Dv_Plus_Ad_total',\n",
      "       'misc_EqPrim_Mt_Inc_total', 'misc_EqPrim_Dv_Inc_total',\n",
      "       'misc_OI_Dv_Minus_Dv_Minus_total',\n",
      "       'misc_EqSec_OpFrac_MMC_MtNumerador_total'],\n",
      "      dtype='object', length=336)\n"
     ]
    }
   ],
   "source": [
    "# Gera√ß√£o dos relat√≥rios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das caracter√≠sticas s√£o as colunas\n",
    "print(\"feature_names: \", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_preprocessed shape: (12765, 336)\n",
      "y_train shape: (12765,)\n"
     ]
    }
   ],
   "source": [
    "# Verifica√ß√£o antes de chamar a fun√ß√£o de treinamento\n",
    "print(f\"X_train_preprocessed shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"y_train shape: {y_train_over.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento dos Modelos usando Otimiza√ß√£o Bayesiana (BayesSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating Logistic Regression with BayesianOptimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=3.2521088005944945, classifier__max_iter=8950, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_features_to_select=50;, score=0.901 total time= 5.8min\n",
      "[CV 1/2] END classifier__C=3.2521088005944945, classifier__max_iter=8950, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_features_to_select=50;, score=0.892 total time= 6.2min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=0.2160217783087772, classifier__max_iter=9269, classifier__penalty=l2, classifier__solver=lbfgs, feature_selection__n_features_to_select=5;, score=0.754 total time= 6.9min\n",
      "[CV 1/2] END classifier__C=0.2160217783087772, classifier__max_iter=9269, classifier__penalty=l2, classifier__solver=lbfgs, feature_selection__n_features_to_select=5;, score=0.755 total time= 7.3min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=2.7364528220782454, classifier__max_iter=2547, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_features_to_select=20;, score=0.842 total time= 6.6min\n",
      "[CV 1/2] END classifier__C=2.7364528220782454, classifier__max_iter=2547, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_features_to_select=20;, score=0.837 total time= 7.0min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=2.5041499136197736, classifier__max_iter=4942, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_features_to_select=50;, score=0.904 total time= 6.4min\n",
      "[CV 1/2] END classifier__C=2.5041499136197736, classifier__max_iter=4942, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_features_to_select=50;, score=0.896 total time= 6.9min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=1.5925169151603527, classifier__max_iter=9454, classifier__penalty=l1, classifier__solver=liblinear, feature_selection__n_features_to_select=40;, score=0.879 total time= 7.2min\n",
      "[CV 1/2] END classifier__C=1.5925169151603527, classifier__max_iter=9454, classifier__penalty=l1, classifier__solver=liblinear, feature_selection__n_features_to_select=40;, score=0.885 total time= 7.4min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=0.7099668574083867, classifier__max_iter=7978, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_features_to_select=30;, score=0.858 total time= 6.6min\n",
      "[CV 1/2] END classifier__C=0.7099668574083867, classifier__max_iter=7978, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_features_to_select=30;, score=0.861 total time= 7.0min\n",
      "BayesianOptimization Best Result for Logistic Regression with rfe: 0.9000078168454282\n",
      "Training and evaluating Logistic Regression with BayesianOptimization and pca:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__C=3.2521088005944945, classifier__max_iter=8950, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_components=50;, score=0.911 total time=   0.9s\n",
      "[CV 2/2] END classifier__C=3.2521088005944945, classifier__max_iter=8950, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_components=50;, score=0.926 total time=   1.0s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=0.2160217783087772, classifier__max_iter=9269, classifier__penalty=l2, classifier__solver=lbfgs, feature_selection__n_components=5;, score=0.711 total time=   0.1s\n",
      "[CV 1/2] END classifier__C=0.2160217783087772, classifier__max_iter=9269, classifier__penalty=l2, classifier__solver=lbfgs, feature_selection__n_components=5;, score=0.713 total time=   0.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=2.7364528220782454, classifier__max_iter=2547, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_components=20;, score=0.842 total time=   0.2s\n",
      "[CV 1/2] END classifier__C=2.7364528220782454, classifier__max_iter=2547, classifier__penalty=l2, classifier__solver=saga, feature_selection__n_components=20;, score=0.835 total time=   0.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__C=2.5041499136197736, classifier__max_iter=4942, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_components=50;, score=0.911 total time=   2.4s\n",
      "[CV 2/2] END classifier__C=2.5041499136197736, classifier__max_iter=4942, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_components=50;, score=0.927 total time=   2.6s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__C=1.5925169151603527, classifier__max_iter=9454, classifier__penalty=l1, classifier__solver=liblinear, feature_selection__n_components=40;, score=0.891 total time=   0.9s\n",
      "[CV 2/2] END classifier__C=1.5925169151603527, classifier__max_iter=9454, classifier__penalty=l1, classifier__solver=liblinear, feature_selection__n_components=40;, score=0.903 total time=   1.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__C=0.7099668574083867, classifier__max_iter=7978, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_components=30;, score=0.860 total time=   0.5s\n",
      "[CV 2/2] END classifier__C=0.7099668574083867, classifier__max_iter=7978, classifier__penalty=l1, classifier__solver=saga, feature_selection__n_components=30;, score=0.870 total time=   0.5s\n",
      "BayesianOptimization Best Result for Logistic Regression with pca: 0.9186859973125261\n",
      "Training and evaluating Decision Tree with BayesianOptimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_features_to_select=10;, score=0.849 total time= 6.3min\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_features_to_select=10;, score=0.847 total time= 6.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_features_to_select=50;, score=0.950 total time= 6.1min\n",
      "[CV 1/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_features_to_select=50;, score=0.949 total time= 6.5min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_features_to_select=20;, score=0.859 total time= 6.5min\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_features_to_select=20;, score=0.857 total time= 6.9min\n",
      "BayesianOptimization Best Result for Decision Tree with rfe: 0.9492839828103463\n",
      "Training and evaluating Decision Tree with BayesianOptimization and pca:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_components=10;, score=0.827 total time=   0.1s\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=8, classifier__min_samples_split=19, feature_selection__n_components=10;, score=0.808 total time=   0.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_components=50;, score=0.938 total time=   0.4s\n",
      "[CV 1/2] END classifier__max_depth=30, classifier__min_samples_leaf=9, classifier__min_samples_split=7, feature_selection__n_components=50;, score=0.918 total time=   0.5s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_components=20;, score=0.838 total time=   0.2s\n",
      "[CV 1/2] END classifier__max_depth=5, classifier__min_samples_leaf=9, classifier__min_samples_split=4, feature_selection__n_components=20;, score=0.823 total time=   0.2s\n",
      "BayesianOptimization Best Result for Decision Tree with pca: 0.9277331165805285\n",
      "Training and evaluating Random Forest with BayesianOptimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=14, classifier__max_features=None, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, feature_selection__n_features_to_select=10;, score=0.972 total time= 6.7min\n",
      "[CV 1/2] END classifier__max_depth=14, classifier__max_features=None, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, feature_selection__n_features_to_select=10;, score=0.969 total time= 7.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=26, classifier__max_features=None, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, feature_selection__n_features_to_select=1;, score=0.948 total time= 6.7min\n",
      "[CV 1/2] END classifier__max_depth=26, classifier__max_features=None, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, feature_selection__n_features_to_select=1;, score=0.948 total time= 7.2min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=15, classifier__max_features=None, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, feature_selection__n_features_to_select=20;, score=0.987 total time= 6.7min\n",
      "[CV 1/2] END classifier__max_depth=15, classifier__max_features=None, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, feature_selection__n_features_to_select=20;, score=0.984 total time= 7.1min\n",
      "BayesianOptimization Best Result for Random Forest with rfe: 0.9851333827422863\n",
      "Training and evaluating Random Forest with BayesianOptimization and pca:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=14, classifier__max_features=None, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, feature_selection__n_components=10;, score=0.967 total time=   5.6s\n",
      "[CV 1/2] END classifier__max_depth=14, classifier__max_features=None, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, feature_selection__n_components=10;, score=0.962 total time=   5.8s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__max_depth=26, classifier__max_features=None, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, feature_selection__n_components=1;, score=0.860 total time=   1.2s\n",
      "[CV 1/2] END classifier__max_depth=26, classifier__max_features=None, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, feature_selection__n_components=1;, score=0.844 total time=   1.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__max_depth=15, classifier__max_features=None, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, feature_selection__n_components=20;, score=0.974 total time=   5.7s\n",
      "[CV 2/2] END classifier__max_depth=15, classifier__max_features=None, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, feature_selection__n_components=20;, score=0.977 total time=   5.7s\n",
      "BayesianOptimization Best Result for Random Forest with pca: 0.9750940707522242\n",
      "Training and evaluating Gradient Boosting with BayesianOptimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__learning_rate=0.08791975218212963, classifier__max_depth=8, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, classifier__subsample=0.7070593162427692, feature_selection__n_features_to_select=10;, score=0.990 total time= 6.7min\n",
      "[CV 1/2] END classifier__learning_rate=0.08791975218212963, classifier__max_depth=8, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, classifier__subsample=0.7070593162427692, feature_selection__n_features_to_select=10;, score=0.988 total time= 7.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__learning_rate=0.16910378755512404, classifier__max_depth=9, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, classifier__subsample=0.5311564704220357, feature_selection__n_features_to_select=1;, score=0.943 total time= 6.8min\n",
      "[CV 1/2] END classifier__learning_rate=0.16910378755512404, classifier__max_depth=9, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, classifier__subsample=0.5311564704220357, feature_selection__n_features_to_select=1;, score=0.950 total time= 7.2min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__learning_rate=0.09451817733721884, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, classifier__subsample=0.7268326719031495, feature_selection__n_features_to_select=5;, score=0.984 total time= 6.7min\n",
      "[CV 1/2] END classifier__learning_rate=0.09451817733721884, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, classifier__subsample=0.7268326719031495, feature_selection__n_features_to_select=5;, score=0.985 total time= 7.1min\n",
      "BayesianOptimization Best Result for Gradient Boosting with rfe: 0.9890792433150639\n",
      "Training and evaluating Gradient Boosting with BayesianOptimization and pca:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__learning_rate=0.08791975218212963, classifier__max_depth=8, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, classifier__subsample=0.7070593162427692, feature_selection__n_components=10;, score=0.976 total time=  24.0s\n",
      "[CV 2/2] END classifier__learning_rate=0.08791975218212963, classifier__max_depth=8, classifier__min_samples_leaf=9, classifier__min_samples_split=8, classifier__n_estimators=218, classifier__subsample=0.7070593162427692, feature_selection__n_components=10;, score=0.982 total time=  24.0s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__learning_rate=0.16910378755512404, classifier__max_depth=9, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, classifier__subsample=0.5311564704220357, feature_selection__n_components=1;, score=0.826 total time=   4.7s\n",
      "[CV 2/2] END classifier__learning_rate=0.16910378755512404, classifier__max_depth=9, classifier__min_samples_leaf=4, classifier__min_samples_split=19, classifier__n_estimators=266, classifier__subsample=0.5311564704220357, feature_selection__n_components=1;, score=0.841 total time=   4.8s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END classifier__learning_rate=0.09451817733721884, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, classifier__subsample=0.7268326719031495, feature_selection__n_components=5;, score=0.969 total time=   6.8s\n",
      "[CV 2/2] END classifier__learning_rate=0.09451817733721884, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=10, classifier__n_estimators=97, classifier__subsample=0.7268326719031495, feature_selection__n_components=5;, score=0.975 total time=   7.0s\n",
      "BayesianOptimization Best Result for Gradient Boosting with pca: 0.9793849524824553\n",
      "Training and evaluating SVM with BayesianOptimization and rfe:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=2.7364528220782454, classifier__gamma=0.00032780432870046914, classifier__kernel=rbf, feature_selection__n_features_to_select=40;, score=0.777 total time= 6.2min\n",
      "[CV 1/2] END classifier__C=2.7364528220782454, classifier__gamma=0.00032780432870046914, classifier__kernel=rbf, feature_selection__n_features_to_select=40;, score=0.766 total time= 6.6min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=2.5041499136197736, classifier__gamma=0.002061045404501547, classifier__kernel=rbf, feature_selection__n_features_to_select=40;, score=0.826 total time= 6.3min\n",
      "[CV 1/2] END classifier__C=2.5041499136197736, classifier__gamma=0.002061045404501547, classifier__kernel=rbf, feature_selection__n_features_to_select=40;, score=0.820 total time= 6.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=1.5925169151603527, classifier__gamma=0.06578232405415442, classifier__kernel=rbf, feature_selection__n_features_to_select=5;, score=0.759 total time= 6.7min\n",
      "[CV 1/2] END classifier__C=1.5925169151603527, classifier__gamma=0.06578232405415442, classifier__kernel=rbf, feature_selection__n_features_to_select=5;, score=0.757 total time= 7.1min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=0.7099668574083867, classifier__gamma=scale, classifier__kernel=linear, feature_selection__n_features_to_select=50;, score=0.908 total time= 6.0min\n",
      "[CV 1/2] END classifier__C=0.7099668574083867, classifier__gamma=scale, classifier__kernel=linear, feature_selection__n_features_to_select=50;, score=0.901 total time= 6.4min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=0.42678505501429925, classifier__gamma=scale, classifier__kernel=linear, feature_selection__n_features_to_select=40;, score=0.882 total time= 6.3min\n",
      "[CV 1/2] END classifier__C=0.42678505501429925, classifier__gamma=scale, classifier__kernel=linear, feature_selection__n_features_to_select=40;, score=0.890 total time= 6.7min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=7.352481813242629, classifier__gamma=scale, classifier__kernel=linear, feature_selection__n_features_to_select=10;, score=0.801 total time= 6.5min\n",
      "[CV 1/2] END classifier__C=7.352481813242629, classifier__gamma=scale, classifier__kernel=linear, feature_selection__n_features_to_select=10;, score=0.807 total time= 6.9min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END classifier__C=0.010253943538922507, classifier__degree=4, classifier__gamma=0.016743576591267018, classifier__kernel=poly, feature_selection__n_features_to_select=30;, score=0.288 total time= 6.4min\n",
      "[CV 1/2] END classifier__C=0.010253943538922507, classifier__degree=4, classifier__gamma=0.016743576591267018, classifier__kernel=poly, feature_selection__n_features_to_select=30;, score=0.273 total time= 6.8min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    }
   ],
   "source": [
    "from bayesian_optimization_training import BayesianOptimizationTraining\n",
    "cv = 2\n",
    "n_iter = 3\n",
    "\n",
    "# Escolher a m√©trica de avalia√ß√£o\n",
    "scoring_metric = 'roc_auc_ovr'  # Pode ser 'f1_macro', 'balanced_accuracy', 'roc_auc_ovr', etc.\n",
    "\n",
    "# Instanciar a classe BayesianOptimizationTraining\n",
    "training = BayesianOptimizationTraining()\n",
    "\n",
    "\n",
    "# Chamar o treinamento com otimiza√ß√£o bayesiana\n",
    "trained_models = training.train_model(\n",
    "    X_train_preprocessed, y_train_over, n_iter=n_iter, cv=cv, scoring=scoring_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avalia√ß√£o dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import evaluation  # Importa o m√≥dulo evaluation\n",
    "importlib.reload(evaluation)  # Recarrega o m√≥dulo evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import Evaluation \n",
    "\n",
    "# Gera√ß√£o dos relat√≥rios\n",
    "feature_names = X_train.columns  # Assumindo que os nomes das caracter√≠sticas s√£o as colunas\n",
    "evaluation_results = Evaluation.evaluate_all_models(trained_models, X_train_preprocessed, y_train_over, X_test_preprocessed, y_test, feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gera√ß√£o dos Relat√≥rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import report_formatter  # Importa o m√≥dulo evaluation\n",
    "importlib.reload(report_formatter)  # Recarrega o m√≥dulo evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from report_formatter import ReportFormatter\n",
    "from file_manager import FileManager\n",
    "\n",
    "directory = \"../output/\"\n",
    "\n",
    "# Impress√£o dos relat√≥rios\n",
    "\n",
    "# Gerar relat√≥rio textual a partir dos resultados de avalia√ß√£o\n",
    "text_report = ReportFormatter.generate_text_report_from_dict(evaluation_results)\n",
    "\n",
    "# Imprimir ou salvar o relat√≥rio\n",
    "FileManager.save_text_file_with_timestamp(text_report, \"bayesian_optimization_report.txt\", directory)\n",
    "\n",
    "# Opcional: Gerar DataFrame detalhado e resumido dos relat√≥rios\n",
    "detailed_df = ReportFormatter.generate_detailed_report_dataframe(evaluation_results)\n",
    "summary_df = ReportFormatter.generate_summary_report_dataframe(evaluation_results)\n",
    "\n",
    "# Salvar os DataFrames como arquivos CSV, se necess√°rio\n",
    "FileManager.save_csv_file_with_timestamp(detailed_df, \"detailed_report.csv\", directory)\n",
    "FileManager.save_csv_file_with_timestamp(summary_df, \"summary_report.csv\", directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando os modelos em arquivos para recupera√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_manager import ModelManager\n",
    "\n",
    "# Caminhos\n",
    "model_dir = \"../models/\"\n",
    "\n",
    "# Salvar todos os modelos\n",
    "saved_models = ModelManager.dump_all_models(trained_models, model_dir)\n",
    "print(\"Modelos salvos:\", saved_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetos_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
